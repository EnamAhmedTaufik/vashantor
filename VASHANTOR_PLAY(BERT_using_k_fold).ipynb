{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "nn8k6qv5P1hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install dataprep"
      ],
      "metadata": {
        "id": "O6ZzcomJP0wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/csebuetnlp/normalizer"
      ],
      "metadata": {
        "id": "fpdKhC18Q5Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pytorch-lightning==2.1.4\n",
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "tWBNEroP-xJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3htvK8w9jCZ",
        "outputId": "bde5eee1-3b09-48fb-edfe-b481f661f193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], encoding='utf-8')\n",
        "        gpu_name = output.strip()\n",
        "        return gpu_name\n",
        "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "        return None\n",
        "print(get_gpu_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5TIYMSa9jAA",
        "outputId": "1b01374d-b6fa-49a8-ac18-527fd4207ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1D1StYK9i9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Mount"
      ],
      "metadata": {
        "id": "LW7oiuVLPyTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUlIqmd_StaD",
        "outputId": "19391368-b375-45f8-ecd7-49da4c15862e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "m_hZ7kfPawO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0pnPOcIA_Re"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoModelForPreTraining, AutoTokenizer\n",
        "from normalizer import normalize\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "#from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n"
      ],
      "metadata": {
        "id": "WVIjBhUp-sg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "GwNwsh2bRvWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ru3sH9BqLG",
        "outputId": "614bd680-7a9b-4a8a-fb35-110772a8808b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "BZtU1z5FH5VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Barishal Train Translation.csv\")\n",
        "ctg_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Chittagong Train Translation.csv\")\n",
        "mymensingh_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Mymensingh Train Translation.csv\")\n",
        "nohakhali_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Noakhali Train Translation.csv\")\n",
        "sylhet_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Sylhet Train Translation.csv\")"
      ],
      "metadata": {
        "id": "JjyEqfqrBqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Barishal  Validation Translation.csv\")\n",
        "ctg_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Chittagong Validation Translation.csv\")\n",
        "mymensingh_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Mymensingh Validation Translation.csv\")\n",
        "nohakhali_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Noakhali Validation Translation.csv\")\n",
        "sylhet_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Sylhet Validation Translation.csv\")"
      ],
      "metadata": {
        "id": "1W5dEm5IMk48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Barishal Test Translation.csv\")\n",
        "ctg_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Chittagong Test Translation.csv\")\n",
        "mymensingh_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Mymensingh Test Translation.csv\")\n",
        "nohakhali_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Noakhali Test Translation.csv\")\n",
        "sylhet_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Sylhet Test Translation.csv\")"
      ],
      "metadata": {
        "id": "hr-qXJb6Ml8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concate VASHANTOR DATASET (Train, valid, test)"
      ],
      "metadata": {
        "id": "Bimyvu64NoE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df = pd.concat([barishal_train_df, barishal_valid_df, barishal_test_df])\n",
        "ctg_train_df = pd.concat([ctg_train_df, ctg_valid_df, ctg_test_df])\n",
        "mymensingh_train_df = pd.concat([mymensingh_train_df, mymensingh_valid_df, mymensingh_test_df])\n",
        "nohakhali_train_df = pd.concat([nohakhali_train_df, nohakhali_valid_df, nohakhali_test_df])\n",
        "sylhet_train_df = pd.concat([sylhet_train_df, sylhet_valid_df, sylhet_test_df])"
      ],
      "metadata": {
        "id": "ID1aOzyFM_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U4ow9qxVBqGK",
        "outputId": "1b4dc213-52af-4702-a3bc-428689d33ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            bangla_speech   \\\n",
              "0                               কেমন আছো ?   \n",
              "1                    আজকে আমার মন ভালো নেই   \n",
              "2                            তুমি কি করো ?   \n",
              "3           এই গরমে আমার কিছু ভালো লাগে না   \n",
              "4  ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল   \n",
              "\n",
              "                                banglish_speech   \\\n",
              "0                                    kemon acho?   \n",
              "1                          ajke amr mon valo nei   \n",
              "2                                 tumi ki koro?    \n",
              "3              ei gorome amar kichu valo lage na   \n",
              "4  cheleti sada ronger ekti shirt pore eshechilo   \n",
              "\n",
              "                             barishal_bangla_speech   \\\n",
              "0                                        আসো কোরোহম?   \n",
              "1                               আইজ মোর মনডা ভালোনা    \n",
              "2                                      ও মোনু হর কি?   \n",
              "3             এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...   \n",
              "\n",
              "                           barishal_banglish_speech  region_name   \\\n",
              "0                                       Aso korohom?    Barishal    \n",
              "1                               aij mor monda valona    Barishal    \n",
              "2                                    o monu horo ki?    Barishal    \n",
              "3           ei thada pora gorome mor kissu vallagena    Barishal    \n",
              "4  polaugga eukka dhola rong er eukka gunji poirr...    Barishal    \n",
              "\n",
              "                       english_speech  \n",
              "0                        How are you?  \n",
              "1          I'm not feeling well today  \n",
              "2                  what are you doing  \n",
              "3   I don't like anything this summer  \n",
              "4  The boy came wearing a white shirt  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ba7af79-b65c-492f-89de-a2b29e52718c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>banglish_speech</th>\n",
              "      <th>barishal_bangla_speech</th>\n",
              "      <th>barishal_banglish_speech</th>\n",
              "      <th>region_name</th>\n",
              "      <th>english_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো ?</td>\n",
              "      <td>kemon acho?</td>\n",
              "      <td>আসো কোরোহম?</td>\n",
              "      <td>Aso korohom?</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>How are you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে আমার মন ভালো নেই</td>\n",
              "      <td>ajke amr mon valo nei</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>aij mor monda valona</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>I'm not feeling well today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তুমি কি করো ?</td>\n",
              "      <td>tumi ki koro?</td>\n",
              "      <td>ও মোনু হর কি?</td>\n",
              "      <td>o monu horo ki?</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>what are you doing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>এই গরমে আমার কিছু ভালো লাগে না</td>\n",
              "      <td>ei gorome amar kichu valo lage na</td>\n",
              "      <td>এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>ei thada pora gorome mor kissu vallagena</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>I don't like anything this summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল</td>\n",
              "      <td>cheleti sada ronger ekti shirt pore eshechilo</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...</td>\n",
              "      <td>polaugga eukka dhola rong er eukka gunji poirr...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>The boy came wearing a white shirt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ba7af79-b65c-492f-89de-a2b29e52718c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ba7af79-b65c-492f-89de-a2b29e52718c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ba7af79-b65c-492f-89de-a2b29e52718c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3689cc1-ca7f-4f87-899f-2fd07d04fb73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3689cc1-ca7f-4f87-899f-2fd07d04fb73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3689cc1-ca7f-4f87-899f-2fd07d04fb73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgix2qADvCY",
        "outputId": "09acb640-18f3-4d7c-89e3-2476d06710ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'barishal_bangla_speech ',\n",
              "       'barishal_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctg_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqtYoUU1D5Iu",
        "outputId": "6a235a68-0a4d-4395-9f9e-f96c996a124e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'chittagong_bangla_speech ',\n",
              "       'chittagong_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mymensingh_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU74zvbPD5F2",
        "outputId": "e645efd6-8019-40b9-c0cc-2b97434abeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'mymensingh_bangla_speech ',\n",
              "       'mymensingh_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nohakhali_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDq4VG8hD5Cu",
        "outputId": "37780a2b-5263-45cf-afa7-8ff25bc5a6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'noakhali_bangla_speech ',\n",
              "       'noakhali_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8ALmdhlD_qb",
        "outputId": "13503529-69f4-4c11-8275-51f9b7219c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'sylhet_bangla_speech ',\n",
              "       'sylhet_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Columns"
      ],
      "metadata": {
        "id": "9rAw9DZVIBK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.drop(columns=['banglish_speech ', 'barishal_banglish_speech ', 'english_speech'], inplace=True)\n",
        "ctg_train_df.drop(columns=['banglish_speech ', 'chittagong_banglish_speech ', 'english_speech'], inplace=True)\n",
        "mymensingh_train_df.drop(columns=['banglish_speech ', 'mymensingh_banglish_speech ', 'english_speech'], inplace=True)\n",
        "nohakhali_train_df.drop(columns=['banglish_speech ', 'noakhali_banglish_speech ', 'english_speech'], inplace=True)\n",
        "sylhet_train_df.drop(columns=['banglish_speech ', 'sylhet_banglish_speech ', 'english_speech'], inplace=True)\n"
      ],
      "metadata": {
        "id": "YtQLkxAVBp-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rename Columns from xyz_bangla_speech to regional_text"
      ],
      "metadata": {
        "id": "7_A0MzI6IFHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.rename(columns={'barishal_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "ctg_train_df.rename(columns={'chittagong_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "mymensingh_train_df.rename(columns={'mymensingh_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "nohakhali_train_df.rename(columns={'noakhali_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "sylhet_train_df.rename(columns={'sylhet_bangla_speech ': 'regional_text'}, inplace=True)"
      ],
      "metadata": {
        "id": "-ZqZXAPdGexC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Topj0NUC23p8",
        "outputId": "17ddf657-e3f4-45ef-9313-3dba36ea929a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'regional_text', 'region_name '], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSu3xJ7Y29a9",
        "outputId": "e21c1780-53b4-4d11-a620-d5ece096648a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sylhet', 'Sylhet '], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '] = sylhet_train_df['region_name '].replace('Sylhet ', 'Sylhet')\n"
      ],
      "metadata": {
        "id": "Fjr5ZRtM3Lm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmBt8n_y3iZ4",
        "outputId": "bc86f0e2-8c98-46a1-9da4-adc320e69fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sylhet'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concate all regional text"
      ],
      "metadata": {
        "id": "YyovFntJINYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([barishal_train_df, ctg_train_df, mymensingh_train_df, nohakhali_train_df, sylhet_train_df])"
      ],
      "metadata": {
        "id": "F34wOGtOBp7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.head(7000)"
      ],
      "metadata": {
        "id": "ga8EJ0e-Bp5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_Gp1klrjJAwj",
        "outputId": "8ef6cca9-4889-4568-b3a3-624ef51c2a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        bangla_speech   \\\n",
              "125                           সে সবসময় মিথ্যা কথা বলতো   \n",
              "126                             সবাই তাকে অনেক ভয় পেতো   \n",
              "127                             কেউ তাকে ভালোবাসতো নাহ   \n",
              "128                                  সে খুবই খারাপ ছিল   \n",
              "129  গ্রামের মানুষরা ছেলেটির থেকে দূরে থাকতে চেষ্টা...   \n",
              "..                                                 ...   \n",
              "370       তুমি কি আমাকে এক গ্লাস পানি এনে দিতে পারবে ?   \n",
              "371                            আমি পারবো না পানি দিতে    \n",
              "372                   তোমার ভাই পড়ালেখাতে অনেক মেধাবি    \n",
              "373               আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা?    \n",
              "374                 সামনের দিকে যেয়ে মেয়েটি অনেক হাসবে   \n",
              "\n",
              "                                         regional_text region_name   \n",
              "125                          হে হখল সময় মিছা মাত মাততো       Sylhet  \n",
              "126                              হখলে তারে খুব ডরাইতো        Sylhet  \n",
              "127                             কেউ তারে বালা পাইতো না       Sylhet  \n",
              "128                                    হে বউত বাদ আছিল       Sylhet  \n",
              "129  গ্রাম ওর মাইনষে ফুয়া ওগুর তনে দূরে থাকার চেষ্ট...       Sylhet  \n",
              "..                                                 ...          ...  \n",
              "370      তুমি কি আমারে এক গ্লাস ফানি এনে দিতায় ফারবা?        Sylhet  \n",
              "371                             আমি পারবো না ফানি দিতে       Sylhet  \n",
              "372                    তোমার ভাই ফড়ালেখাতে বহুত মেধাবি       Sylhet  \n",
              "373                আইচ্চা কও দেখি বাঙলাদেশো কয়টা জেলা?       Sylhet  \n",
              "374                 সামনর দিকে যাইয়া ফুড়িটা বহুত হাসবো       Sylhet  \n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c38f2778-30be-4041-9dbe-818cb3e42ae6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>সে সবসময় মিথ্যা কথা বলতো</td>\n",
              "      <td>হে হখল সময় মিছা মাত মাততো</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>সবাই তাকে অনেক ভয় পেতো</td>\n",
              "      <td>হখলে তারে খুব ডরাইতো</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>কেউ তাকে ভালোবাসতো নাহ</td>\n",
              "      <td>কেউ তারে বালা পাইতো না</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>সে খুবই খারাপ ছিল</td>\n",
              "      <td>হে বউত বাদ আছিল</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>গ্রামের মানুষরা ছেলেটির থেকে দূরে থাকতে চেষ্টা...</td>\n",
              "      <td>গ্রাম ওর মাইনষে ফুয়া ওগুর তনে দূরে থাকার চেষ্ট...</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>তুমি কি আমাকে এক গ্লাস পানি এনে দিতে পারবে ?</td>\n",
              "      <td>তুমি কি আমারে এক গ্লাস ফানি এনে দিতায় ফারবা?</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>আমি পারবো না পানি দিতে</td>\n",
              "      <td>আমি পারবো না ফানি দিতে</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>তোমার ভাই পড়ালেখাতে অনেক মেধাবি</td>\n",
              "      <td>তোমার ভাই ফড়ালেখাতে বহুত মেধাবি</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা?</td>\n",
              "      <td>আইচ্চা কও দেখি বাঙলাদেশো কয়টা জেলা?</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>সামনের দিকে যেয়ে মেয়েটি অনেক হাসবে</td>\n",
              "      <td>সামনর দিকে যাইয়া ফুড়িটা বহুত হাসবো</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38f2778-30be-4041-9dbe-818cb3e42ae6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c38f2778-30be-4041-9dbe-818cb3e42ae6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c38f2778-30be-4041-9dbe-818cb3e42ae6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4fb3f706-02b4-406d-9ce8-2cad61b47a56\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fb3f706-02b4-406d-9ce8-2cad61b47a56')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4fb3f706-02b4-406d-9ce8-2cad61b47a56 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode region_name column"
      ],
      "metadata": {
        "id": "FF0c56bDIgPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HHgsANNJNYa",
        "outputId": "ea12f767-5be3-4049-919a-6d5d334767fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'regional_text', 'region_name '], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'bangla_speech ': 'bangla_speech'}, inplace=True)\n",
        "df.rename(columns={'region_name ': 'region_name'}, inplace=True)"
      ],
      "metadata": {
        "id": "LoeSXWm5RvkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['region_encoded'] = label_encoder.fit_transform(df['region_name'])"
      ],
      "metadata": {
        "id": "fbZs91_7Bp3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_name'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ6_TArJIy6Q",
        "outputId": "7ac407dd-78c2-4ce6-966c-da7b8d450e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Barishal ', 'Chittagong', 'Mymensingh', 'Noakhali', 'Sylhet'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_encoded'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFhhenUbJVoB",
        "outputId": "1e1d9c97-8957-4494-a172-6967c7894b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.drop(columns=['region_name '], inplace=True)"
      ],
      "metadata": {
        "id": "nAWyh49dJieR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "jmYcIrA-KRxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('/content/drive/MyDrive/On going Research/VASHANTOR/combined_regional_text.csv', index=False)"
      ],
      "metadata": {
        "id": "69mMI0isi9hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Normalize"
      ],
      "metadata": {
        "id": "2af10LpEQeYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Puntuation**"
      ],
      "metadata": {
        "id": "F3iovqA0Ub-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations(text):\n",
        "  whitespace = re.compile(u\"[\\s\\u0020\\u00a0\\u1680\\u180e\\u202f\\u205f\\u3000\\u2000-\\u200d]+\", re.UNICODE)\n",
        "  bangla_fullstop = u\"\\u0964\"\n",
        "  text = re.sub(r'(^|\\s)@(\\w+)', r'\\1@user', text)\n",
        "  text = re.sub(r'\\bhttp?s://\\S+\\b', '', text)\n",
        "  punctSeq = u\"['\\\"“”‘’]+|[.?!,…]+|[:;]+\"\n",
        "  punc = u\"[(),$%^&*+={}\\[\\]:\\\"\\৷|\\'\\~`<>/,¦!?½£¶¼©⅐⅑⅒⅓⅔⅕⅖⅗⅘⅙⅚⅛⅜⅝⅞⅟↉¤¿º;-]+\"\n",
        "  text = whitespace.sub(\" \", text).strip()\n",
        "  text = re.sub(punctSeq, \" \", text)\n",
        "  text = re.sub(bangla_fullstop, \" \", text)\n",
        "  text = re.sub(punc, \" \", text)\n",
        "  text = re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]', ' ', text)\n",
        "  result = re.sub(r'\\b[a-zA-Z]+\\b', '', text)\n",
        "  text=text.replace(\"\\\\\", \" \")\n",
        "  normalized = normalize(text)\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "v3cVC2_zQhtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bangla_speech'] = df['bangla_speech'].apply(remove_punctuations)\n",
        "df['regional_text'] = df['regional_text'].apply(remove_punctuations)"
      ],
      "metadata": {
        "id": "Kng1G4QgT0Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis Data"
      ],
      "metadata": {
        "id": "MOD2qhPBKWyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "teitE7ePQhyG",
        "outputId": "7b5e2045-40ca-4da4-8b31-e3e55ee58953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       bangla_speech  \\\n",
              "0                                         কেমন আছো     \n",
              "1                              আজকে আমার মন ভালো নেই   \n",
              "2                                      তুমি কি করো     \n",
              "3                     এই গরমে আমার কিছু ভালো লাগে না   \n",
              "4            ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল   \n",
              "5  মেয়েটি লাল রঙয়ের শাড়ি পরে আমার সাথে দেখা করতে ...   \n",
              "6                      ছেলেটি সিলেট থেকে ঢাকায় এসেছে   \n",
              "7     মেয়েটি সিলেট থেকে আসা এই ছেলেটিকে অনেক ভালবাসে   \n",
              "8          ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি   \n",
              "9  মেয়েটি তাঁর সব স্বপ্নের মধ্যে ছেলেটাকে কল্পনা করে   \n",
              "\n",
              "                                       regional_text region_name  \\\n",
              "0                                        আসো কোরোহম    Barishal    \n",
              "1                                আইজ মোর মনডা ভালোনা   Barishal    \n",
              "2                                      ও মোনু হর কি    Barishal    \n",
              "3             এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   Barishal    \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...   Barishal    \n",
              "5  মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...   Barishal    \n",
              "6                   পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে   Barishal    \n",
              "7  মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...   Barishal    \n",
              "8      পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই   Barishal    \n",
              "9  মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...   Barishal    \n",
              "\n",
              "   region_encoded  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  \n",
              "5               0  \n",
              "6               0  \n",
              "7               0  \n",
              "8               0  \n",
              "9               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94639bb8-9a69-4662-9fb6-9fa5dab90cb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "      <th>region_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>আসো কোরোহম</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে আমার মন ভালো নেই</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তুমি কি করো</td>\n",
              "      <td>ও মোনু হর কি</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>এই গরমে আমার কিছু ভালো লাগে না</td>\n",
              "      <td>এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>মেয়েটি লাল রঙয়ের শাড়ি পরে আমার সাথে দেখা করতে ...</td>\n",
              "      <td>মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ছেলেটি সিলেট থেকে ঢাকায় এসেছে</td>\n",
              "      <td>পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>মেয়েটি সিলেট থেকে আসা এই ছেলেটিকে অনেক ভালবাসে</td>\n",
              "      <td>মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি</td>\n",
              "      <td>পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>মেয়েটি তাঁর সব স্বপ্নের মধ্যে ছেলেটাকে কল্পনা করে</td>\n",
              "      <td>মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94639bb8-9a69-4662-9fb6-9fa5dab90cb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94639bb8-9a69-4662-9fb6-9fa5dab90cb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94639bb8-9a69-4662-9fb6-9fa5dab90cb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84dfa472-4b78-4a3d-89d3-ffabfd9aaa18\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84dfa472-4b78-4a3d-89d3-ffabfd9aaa18')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84dfa472-4b78-4a3d-89d3-ffabfd9aaa18 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Stopwords**"
      ],
      "metadata": {
        "id": "lJmwHybEUhN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('bengali'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcgEU08a6oz",
        "outputId": "9919fd6d-7c93-4e66-a2a8-9ef352ae3971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stop_words_remover(text):\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    without_stop_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    without_stop_word_text = ' '.join(without_stop_words)\n",
        "\n",
        "    return without_stop_word_text\n"
      ],
      "metadata": {
        "id": "3M-MpbxPa5i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bangla_speech'] = df['bangla_speech'].apply(stop_words_remover)\n",
        "df['regional_text'] = df['regional_text'].apply(stop_words_remover)"
      ],
      "metadata": {
        "id": "rOiSw2GaaUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gF9iPilzbgM-",
        "outputId": "3bc2e439-b884-49fb-805b-aaf8e5a33cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               bangla_speech  \\\n",
              "0                                   কেমন আছো   \n",
              "1                               আজকে মন ভালো   \n",
              "2                                        করো   \n",
              "3                             গরমে ভালো লাগে   \n",
              "4             ছেলেটি সাদা রঙয়ের শার্ট এসেছিল   \n",
              "5          মেয়েটি লাল রঙয়ের শাড়ি সাথে এসেছিল   \n",
              "6                   ছেলেটি সিলেট ঢাকায় এসেছে   \n",
              "7          মেয়েটি সিলেট আসা ছেলেটিকে ভালবাসে   \n",
              "8  ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি   \n",
              "9            মেয়েটি স্বপ্নের ছেলেটাকে কল্পনা   \n",
              "\n",
              "                                       regional_text region_name  \\\n",
              "0                                         আসো কোরোহম   Barishal    \n",
              "1                                আইজ মোর মনডা ভালোনা   Barishal    \n",
              "2                                            মোনু হর   Barishal    \n",
              "3                থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   Barishal    \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এউক্কা গুন্জি পইর্রা আইসেল   Barishal    \n",
              "5  মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...   Barishal    \n",
              "6                   পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে   Barishal    \n",
              "7  মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...   Barishal    \n",
              "8      পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই   Barishal    \n",
              "9  মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...   Barishal    \n",
              "\n",
              "   region_encoded  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  \n",
              "5               0  \n",
              "6               0  \n",
              "7               0  \n",
              "8               0  \n",
              "9               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a789df5c-140a-436c-ad3f-d24a3266b576\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "      <th>region_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>আসো কোরোহম</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে মন ভালো</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>করো</td>\n",
              "      <td>মোনু হর</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>গরমে ভালো লাগে</td>\n",
              "      <td>থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের শার্ট এসেছিল</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এউক্কা গুন্জি পইর্রা আইসেল</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>মেয়েটি লাল রঙয়ের শাড়ি সাথে এসেছিল</td>\n",
              "      <td>মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ছেলেটি সিলেট ঢাকায় এসেছে</td>\n",
              "      <td>পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>মেয়েটি সিলেট আসা ছেলেটিকে ভালবাসে</td>\n",
              "      <td>মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি</td>\n",
              "      <td>পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>মেয়েটি স্বপ্নের ছেলেটাকে কল্পনা</td>\n",
              "      <td>মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a789df5c-140a-436c-ad3f-d24a3266b576')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a789df5c-140a-436c-ad3f-d24a3266b576 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a789df5c-140a-436c-ad3f-d24a3266b576');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5660d5e6-024b-40d6-baaa-48226c81894d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5660d5e6-024b-40d6-baaa-48226c81894d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5660d5e6-024b-40d6-baaa-48226c81894d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kt427H5KThU",
        "outputId": "91e00b38-c6a2-43a2-da55-870c494b7b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBvkw17O4Y8",
        "outputId": "44ab5d51-f928-4e2e-92ad-9b4585829f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 12500 entries, 0 to 374\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   bangla_speech   12500 non-null  object\n",
            " 1   regional_text   12500 non-null  object\n",
            " 2   region_name     12500 non-null  object\n",
            " 3   region_encoded  12500 non-null  int64 \n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 488.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_name'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IogpvwGI11l7",
        "outputId": "94c67ae9-94b4-428d-bc33-b53229d2d441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Barishal      2500\n",
              "Chittagong    2500\n",
              "Mymensingh    2500\n",
              "Noakhali      2500\n",
              "Sylhet        2500\n",
              "Name: region_name, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJfgIOCPNJC",
        "outputId": "f4f843fb-3273-4be9-ca85-5c928c2c87af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bangla_speech     0\n",
              "regional_text     0\n",
              "region_name       0\n",
              "region_encoded    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_regions = df['region_name'].value_counts()\n",
        "plt.figure(figsize=(6, 6))\n",
        "unique_regions.plot(kind='bar', color='skyblue')\n",
        "plt.title('Count of Unique Region Names')\n",
        "plt.xlabel('Region Name')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "ws2hUFRTKefk",
        "outputId": "03d8f824-24c3-41e2-ce22-d318517bacd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To implement model"
      ],
      "metadata": {
        "id": "Cgxrr7r4Ah9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'regional_text': 'Data'}, inplace=True)\n",
        "df.rename(columns={'region_encoded': 'Label'}, inplace=True)"
      ],
      "metadata": {
        "id": "rWpqu261AhoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "jMhYMjyQAvC8",
        "outputId": "6910961e-c1c8-42de-ed11-154862e08f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  bangla_speech        Data region_name  Label\n",
              "0      কেমন আছো  আসো কোরোহম   Barishal       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce0ba263-b656-49a2-ac3c-fcd0de50f858\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>Data</th>\n",
              "      <th>region_name</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>আসো কোরোহম</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce0ba263-b656-49a2-ac3c-fcd0de50f858')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce0ba263-b656-49a2-ac3c-fcd0de50f858 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce0ba263-b656-49a2-ac3c-fcd0de50f858');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Barishal', 'Chittagong','Mymensingh','Noakhali','Sylhet']"
      ],
      "metadata": {
        "id": "hr-dOVft7mto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Valid-Test"
      ],
      "metadata": {
        "id": "ib_Ofs5O8_lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop(columns=['Label','bangla_speech','region_name'])\n",
        "y = df['Label']\n",
        "\n",
        "df_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "df_test, df_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the sizes of the resulting datasets\n",
        "print(\"Training set size:\", len(df_train))\n",
        "print(\"Testing set size:\", len(df_test))\n",
        "print(\"Validation set size:\", len(df_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-4Rd5Ep9DZI",
        "outputId": "ef409d13-90fd-4561-ccf5-5db39867fad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 9375\n",
            "Testing set size: 2500\n",
            "Validation set size: 625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train, y_train], axis=1)\n",
        "df_test = pd.concat([df_test, y_test], axis=1)\n",
        "df_val = pd.concat([df_val, y_val], axis=1)"
      ],
      "metadata": {
        "id": "TqemmHFABrBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer bert"
      ],
      "metadata": {
        "id": "3APxXYrDS85N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"csebuetnlp/banglabert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "jZfdHo735Awg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "Wcz1K8yP5HbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, comments, targets, tokenizer, max_len):\n",
        "    self.comments = comments\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comments)\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.comments[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'Data': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "u9wRy5pD8EdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmo-svdX8PlQ",
        "outputId": "d5c960be-3f2e-494c-d9ce-a5bbdb71eb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9375, 2), (625, 2), (2500, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    comments=df.Data.to_numpy(),\n",
        "    targets=df.Label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len,\n",
        "\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=True\n",
        "  )"
      ],
      "metadata": {
        "id": "UNl1EIoK8SSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNIS8cdn8UnG",
        "outputId": "136c3946-cfad-4120-d52d-a3e40f668df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_0HrOWu8XNi",
        "outputId": "453ce2d8-e4c6-4843-f590-f6c29f45caa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Data', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX6ijgPU8ZXz",
        "outputId": "fd7acb69-7b51-424b-bba9-7b5ffdc7978d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = AutoModelForPreTraining.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "VoQnAw7K8bdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(sentimentClassifier, self).__init__()\n",
        "        self.electra = AutoModelForPreTraining.from_pretrained(model_name)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(128, n_classes)  # Adjust the input size\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        pooled_output = outputs.logits  # Access logits for pooled output\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n"
      ],
      "metadata": {
        "id": "LD1DPU6b8jyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "wAVVIZ_M8jwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5M8EGn8jtf",
        "outputId": "7d018815-58d8-48d8-b6aa-0a6aa8dfba4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=True)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=4,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsiwzaFx8jrL",
        "outputId": "e3fd58eb-2cf0-4d67-81a6-f78e97912cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  #tqdm for progress monitoring\n",
        "  data_loader = tqdm(data_loader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Update tqdm description with the current loss\n",
        "    data_loader.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "7R2IPh5J83R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "\n",
        "    data_loader = tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Update tqdm description with the current loss\n",
        "            data_loader.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "WvbOHR-z83PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "k = 5\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Iterate over each fold\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df_train)):\n",
        "    print(f'Fold {fold + 1}/{k}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Split data into training and validation sets for this fold\n",
        "    train_fold = df_train.iloc[train_idx]\n",
        "    val_fold = df_train.iloc[val_idx]\n",
        "\n",
        "    # Create data loaders for this fold\n",
        "    train_data_loader = create_data_loader(train_fold, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "    val_data_loader = create_data_loader(val_fold, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(train_fold))\n",
        "        print(f'\\nTrain loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    # Evaluate the model on the validation set for this fold\n",
        "    val_acc, val_loss = eval_model(model, val_data_loader, loss_fn, device, len(val_fold))\n",
        "    print(f'\\nVal loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "    # Store performance metrics for this fold\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "# Calculate average performance metrics across all folds\n",
        "avg_train_accuracy = sum(train_accuracies) / k\n",
        "avg_val_accuracy = sum(val_accuracies) / k\n",
        "\n",
        "print(f'\\nAverage Train Accuracy: {avg_train_accuracy}')\n",
        "print(f'Average Validation Accuracy: {avg_val_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkjxIfbZ83MI",
        "outputId": "dbf3f1aa-5cf7-45f6-81ec-1a0a34f3230f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:55<00:00,  2.67batch/s, loss=1.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 1.3209733333287716 accuracy 0.4462666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.716]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.7163310259707701 accuracy 0.7234666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.456]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.45644010030734006 accuracy 0.8340000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/118 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 118/118 [00:15<00:00,  7.53batch/s, loss=0.514]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val loss 0.5142274505569268 accuracy 0.8330666666666667\n",
            "Fold 2/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.70batch/s, loss=0.388]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.38828830178906476 accuracy 0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.364653123546638 accuracy 0.8684000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:53<00:00,  2.70batch/s, loss=0.364]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.36410964591734446 accuracy 0.8689333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/118 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 118/118 [00:15<00:00,  7.56batch/s, loss=0.244]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val loss 0.24427131271597502 accuracy 0.9194666666666668\n",
            "Fold 3/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.3651799878188923 accuracy 0.8665333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.36955284454953125 accuracy 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.3738719433554009 accuracy 0.8682666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/118 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 118/118 [00:15<00:00,  7.48batch/s, loss=0.226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val loss 0.22608327473734774 accuracy 0.9226666666666667\n",
            "Fold 4/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.37085629998446146 accuracy 0.8686666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.368]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.36836734106506047 accuracy 0.8686666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.369]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.3693174740998571 accuracy 0.8708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/118 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 118/118 [00:15<00:00,  7.51batch/s, loss=0.243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val loss 0.2427511472458225 accuracy 0.9152\n",
            "Fold 5/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.3710902084145687 accuracy 0.8678666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.3736635673441676 accuracy 0.8652000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/469 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 469/469 [02:54<00:00,  2.69batch/s, loss=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.3737104547692578 accuracy 0.8657333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/118 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 118/118 [00:15<00:00,  7.48batch/s, loss=0.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val loss 0.23003637965993515 accuracy 0.9173333333333333\n",
            "\n",
            "Average Train Accuracy: 0.8615466666666667\n",
            "Average Validation Accuracy: 0.9015466666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQmpaKiCg6K",
        "outputId": "fd4ac73b-ac2d-4346-b0bd-925b07a82ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/157 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 157/157 [00:21<00:00,  7.20batch/s, loss=0.579]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8228000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  toxic_comments = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"Data\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      toxic_comments.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return toxic_comments, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "Nmyx3bkDRYuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIcGzGVFRgNr",
        "outputId": "aa878d42-1334-42f9-a2a2-549f06353e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names,digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtVHMfSpRiIS",
        "outputId": "c651dfd3-13a9-4208-f4c7-6ccdefe0e31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Barishal     0.8611    0.8611    0.8611       511\n",
            "  Chittagong     0.9355    0.8320    0.8807       488\n",
            "  Mymensingh     0.7572    0.8694    0.8094       513\n",
            "    Noakhali     0.7579    0.7625    0.7602       501\n",
            "      Sylhet     0.8290    0.7864    0.8072       487\n",
            "\n",
            "    accuracy                         0.8228      2500\n",
            "   macro avg     0.8281    0.8223    0.8237      2500\n",
            "weighted avg     0.8274    0.8228    0.8236      2500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_percentage = accuracy * 100\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Define the custom palette\n",
        "custom_palette = sns.light_palette(\"DarkOliveGreen\", as_cmap=True)\n",
        "# Define custom font dictionary for title and labels\n",
        "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
        "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 10}\n",
        "\n",
        "# Create heatmap with annotations and colormap\n",
        "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,\n",
        "                      xticklabels=class_names, yticklabels=class_names,\n",
        "                      annot_kws={\"family\": \"Serif\", 'color':'black','weight': 'bold', 'size': 13})\n",
        "\n",
        "# Set x and y labels with the custom font dictionary\n",
        "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
        "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
        "heatmap.set_title('Sentiment classification \\nAccuracy: {:.2f}%'.format(accuracy_percentage),\n",
        "                  fontdict=font, pad=12)\n",
        "\n",
        "# Set font properties for tick labels on both axes\n",
        "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
        "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
        "\n",
        "# Create a color bar to indicate the scale\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=10)\n",
        "# Adjust padding between x-axis label and x-axis ticks\n",
        "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "akmWxmGmRlkb",
        "outputId": "f13abad2-74f8-47b6-b053-1d3cee707a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aBb4PviNUxRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}