{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17360b7ef07640dca2931ebb7a891841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e2310e5f5ff4105a48b76ab784d068c",
              "IPY_MODEL_19886869b4b94802a612f44ebb299849",
              "IPY_MODEL_1681e6159a694e90bcc26e94afa5a9a9"
            ],
            "layout": "IPY_MODEL_1eabe4aa8d5d436cba147f02475cc0bc"
          }
        },
        "8e2310e5f5ff4105a48b76ab784d068c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8464ab553314462fbdaf5672138ca7c3",
            "placeholder": "​",
            "style": "IPY_MODEL_583401a6954c412db6d2155a14626aed",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "19886869b4b94802a612f44ebb299849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1e74196bab54bfcaaa147a1895d9aca",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6694c874a964a2ba45061a0789b5bb2",
            "value": 119
          }
        },
        "1681e6159a694e90bcc26e94afa5a9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592692554e7848109596aae2fe6fc09c",
            "placeholder": "​",
            "style": "IPY_MODEL_f48deab31563474f842c720a4b577fd5",
            "value": " 119/119 [00:00&lt;00:00, 7.61kB/s]"
          }
        },
        "1eabe4aa8d5d436cba147f02475cc0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8464ab553314462fbdaf5672138ca7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583401a6954c412db6d2155a14626aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1e74196bab54bfcaaa147a1895d9aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6694c874a964a2ba45061a0789b5bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "592692554e7848109596aae2fe6fc09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48deab31563474f842c720a4b577fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d93e9754e443b4b5cba30b8d80cea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef6cab0ad32e46129cd74d4f594c70ba",
              "IPY_MODEL_e30a8dd8b13a4d7c8ff71ba152292905",
              "IPY_MODEL_b3a29671a0a8473eae45cdb35540b7eb"
            ],
            "layout": "IPY_MODEL_b7ef822eeff349cf88197bd881fa2228"
          }
        },
        "ef6cab0ad32e46129cd74d4f594c70ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f6230a4e4d6434bba7981376b95bf78",
            "placeholder": "​",
            "style": "IPY_MODEL_d722a9d579d448d591b9d348a697c63f",
            "value": "config.json: 100%"
          }
        },
        "e30a8dd8b13a4d7c8ff71ba152292905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43de5aa767d41c991c61caf7816f9f9",
            "max": 874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be998074d37448789b0640c73dc27e41",
            "value": 874
          }
        },
        "b3a29671a0a8473eae45cdb35540b7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c72beccc574030921ed2f1b91bac4d",
            "placeholder": "​",
            "style": "IPY_MODEL_7c8949c867044ea9b6e2cff115cbb679",
            "value": " 874/874 [00:00&lt;00:00, 67.9kB/s]"
          }
        },
        "b7ef822eeff349cf88197bd881fa2228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f6230a4e4d6434bba7981376b95bf78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d722a9d579d448d591b9d348a697c63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43de5aa767d41c991c61caf7816f9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be998074d37448789b0640c73dc27e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3c72beccc574030921ed2f1b91bac4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8949c867044ea9b6e2cff115cbb679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cfed3bc646a4bb482d257f42e4b5577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73ef010a36474f4f8928b2433417ca36",
              "IPY_MODEL_c6a6fa6937fb4707be1257f522fdd6c3",
              "IPY_MODEL_73683e03d80742ca88d8e46fae1a8dc8"
            ],
            "layout": "IPY_MODEL_4c5d170f58cb48f2b44a46892dbd26b4"
          }
        },
        "73ef010a36474f4f8928b2433417ca36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9609db4e4045c7a1175b88e2654b49",
            "placeholder": "​",
            "style": "IPY_MODEL_2f594ed2cc7d49baa7208adb1f8325e2",
            "value": "vocab.txt: 100%"
          }
        },
        "c6a6fa6937fb4707be1257f522fdd6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78ecb11a0eb41e8b88ce2e1df52bf7e",
            "max": 366256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aebb5edd283844a0a1fe41b2b5948075",
            "value": 366256
          }
        },
        "73683e03d80742ca88d8e46fae1a8dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2537105d5d4249f197b39f615e47d703",
            "placeholder": "​",
            "style": "IPY_MODEL_1c54cf4d3ae44ee7a5c5c9c5837b7ccd",
            "value": " 366k/366k [00:00&lt;00:00, 4.19MB/s]"
          }
        },
        "4c5d170f58cb48f2b44a46892dbd26b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9609db4e4045c7a1175b88e2654b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f594ed2cc7d49baa7208adb1f8325e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78ecb11a0eb41e8b88ce2e1df52bf7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aebb5edd283844a0a1fe41b2b5948075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2537105d5d4249f197b39f615e47d703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c54cf4d3ae44ee7a5c5c9c5837b7ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e036a9e54c34d5e962999939cba56ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4ef2eca3e774932ab6ba814c2810944",
              "IPY_MODEL_a502c20318004769a101a5048a01d8ce",
              "IPY_MODEL_27448499e043416b87c9db04cd9dd64f"
            ],
            "layout": "IPY_MODEL_c773441014a54719bd0800104d7021fe"
          }
        },
        "d4ef2eca3e774932ab6ba814c2810944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce58b5404294d6196bc49c4e8e05578",
            "placeholder": "​",
            "style": "IPY_MODEL_405f27e33390440cab31be1007601639",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a502c20318004769a101a5048a01d8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1100d1eaf190414a9fffbbdc3f23c798",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98d1c1c2639e4569ad63551b83ef17cd",
            "value": 112
          }
        },
        "27448499e043416b87c9db04cd9dd64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f4c8e55315b46a0ba2bde28079f7c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_0fcdd1a0806b42b882288f8640754786",
            "value": " 112/112 [00:00&lt;00:00, 9.34kB/s]"
          }
        },
        "c773441014a54719bd0800104d7021fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce58b5404294d6196bc49c4e8e05578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405f27e33390440cab31be1007601639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1100d1eaf190414a9fffbbdc3f23c798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d1c1c2639e4569ad63551b83ef17cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f4c8e55315b46a0ba2bde28079f7c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcdd1a0806b42b882288f8640754786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4de7414f452e4baabd302680cb562d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c16c2f800ad448ae92b16e768713fe3f",
              "IPY_MODEL_48aa0d3d97b54f19ab41c3243947a385",
              "IPY_MODEL_0c229ddd416d4fc9863454929c573a8a"
            ],
            "layout": "IPY_MODEL_bf5ad777a7a940baa79d06931c98e101"
          }
        },
        "c16c2f800ad448ae92b16e768713fe3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd28990aedd4dfd9d1c3976c1523ff4",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff67cbee5324308bc4e2da4bae018f5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "48aa0d3d97b54f19ab41c3243947a385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0552b01741474455acf4ed834a887a04",
            "max": 442558687,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb4c3d211c8d4c7c825bc3c0b4f9614b",
            "value": 442558687
          }
        },
        "0c229ddd416d4fc9863454929c573a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fa095e8b731425fa629879e29dfc55a",
            "placeholder": "​",
            "style": "IPY_MODEL_0b66705ec7d74c648b619e49fa3db9a5",
            "value": " 443M/443M [00:07&lt;00:00, 63.8MB/s]"
          }
        },
        "bf5ad777a7a940baa79d06931c98e101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd28990aedd4dfd9d1c3976c1523ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff67cbee5324308bc4e2da4bae018f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0552b01741474455acf4ed834a887a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb4c3d211c8d4c7c825bc3c0b4f9614b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fa095e8b731425fa629879e29dfc55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b66705ec7d74c648b619e49fa3db9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "nn8k6qv5P1hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install dataprep"
      ],
      "metadata": {
        "id": "O6ZzcomJP0wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer --quiet"
      ],
      "metadata": {
        "id": "fpdKhC18Q5Mj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52de536e-2a8d-4212-d27a-15eea9e8c257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.1.4 --quiet\n",
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "tWBNEroP-xJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc659e38-7e73-4066-e4dd-967e438aab66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3htvK8w9jCZ",
        "outputId": "5702d10f-ffa8-42b4-de9b-3a2d52349e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], encoding='utf-8')\n",
        "        gpu_name = output.strip()\n",
        "        return gpu_name\n",
        "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "        return None\n",
        "print(get_gpu_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5TIYMSa9jAA",
        "outputId": "db4c4f08-a6fb-4047-89e3-128931c187fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Mount"
      ],
      "metadata": {
        "id": "LW7oiuVLPyTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUlIqmd_StaD",
        "outputId": "65d58a03-3140-4be2-85f0-5668206c3b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "m_hZ7kfPawO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0pnPOcIA_Re"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoModelForPreTraining, AutoTokenizer\n",
        "from normalizer import normalize\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "#from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n"
      ],
      "metadata": {
        "id": "WVIjBhUp-sg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "GwNwsh2bRvWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ru3sH9BqLG",
        "outputId": "9eacb0c2-f873-4c7e-fbe0-2d5ae5e523da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "BZtU1z5FH5VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Train/Barishal Train Translation.csv\")\n",
        "ctg_train_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Train/Chittagong Train Translation.csv\")\n",
        "mymensingh_train_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Train/Mymensingh Train Translation.csv\")\n",
        "nohakhali_train_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Train/Noakhali Train Translation.csv\")\n",
        "sylhet_train_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Train/Sylhet Train Translation.csv\")"
      ],
      "metadata": {
        "id": "JjyEqfqrBqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_valid_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Validation/Barishal  Validation Translation.csv\")\n",
        "ctg_valid_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Validation/Chittagong Validation Translation.csv\")\n",
        "mymensingh_valid_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Validation/Mymensingh Validation Translation.csv\")\n",
        "nohakhali_valid_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Validation/Noakhali Validation Translation.csv\")\n",
        "sylhet_valid_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Validation/Sylhet Validation Translation.csv\")"
      ],
      "metadata": {
        "id": "1W5dEm5IMk48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_test_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Test/Barishal Test Translation.csv\")\n",
        "ctg_test_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Test/Chittagong Test Translation.csv\")\n",
        "mymensingh_test_df =  pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Test/Mymensingh Test Translation.csv\")\n",
        "nohakhali_test_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Test/Noakhali Test Translation.csv\")\n",
        "sylhet_test_df = pd.read_csv(\"/content/drive/MyDrive/VASHANTOR/Test/Sylhet Test Translation.csv\")"
      ],
      "metadata": {
        "id": "hr-qXJb6Ml8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concate VASHANTOR DATASET (Train, valid, test)"
      ],
      "metadata": {
        "id": "Bimyvu64NoE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df = pd.concat([barishal_train_df, barishal_valid_df, barishal_test_df])\n",
        "ctg_train_df = pd.concat([ctg_train_df, ctg_valid_df, ctg_test_df])\n",
        "mymensingh_train_df = pd.concat([mymensingh_train_df, mymensingh_valid_df, mymensingh_test_df])\n",
        "nohakhali_train_df = pd.concat([nohakhali_train_df, nohakhali_valid_df, nohakhali_test_df])\n",
        "sylhet_train_df = pd.concat([sylhet_train_df, sylhet_valid_df, sylhet_test_df])"
      ],
      "metadata": {
        "id": "ID1aOzyFM_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U4ow9qxVBqGK",
        "outputId": "6958b841-760b-4e11-e9c7-ce0b463925de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            bangla_speech   \\\n",
              "0                               কেমন আছো ?   \n",
              "1                    আজকে আমার মন ভালো নেই   \n",
              "2                            তুমি কি করো ?   \n",
              "3           এই গরমে আমার কিছু ভালো লাগে না   \n",
              "4  ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল   \n",
              "\n",
              "                                banglish_speech   \\\n",
              "0                                    kemon acho?   \n",
              "1                          ajke amr mon valo nei   \n",
              "2                                 tumi ki koro?    \n",
              "3              ei gorome amar kichu valo lage na   \n",
              "4  cheleti sada ronger ekti shirt pore eshechilo   \n",
              "\n",
              "                             barishal_bangla_speech   \\\n",
              "0                                        আসো কোরোহম?   \n",
              "1                               আইজ মোর মনডা ভালোনা    \n",
              "2                                      ও মোনু হর কি?   \n",
              "3             এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...   \n",
              "\n",
              "                           barishal_banglish_speech  region_name   \\\n",
              "0                                       Aso korohom?    Barishal    \n",
              "1                               aij mor monda valona    Barishal    \n",
              "2                                    o monu horo ki?    Barishal    \n",
              "3           ei thada pora gorome mor kissu vallagena    Barishal    \n",
              "4  polaugga eukka dhola rong er eukka gunji poirr...    Barishal    \n",
              "\n",
              "                       english_speech  \n",
              "0                        How are you?  \n",
              "1          I'm not feeling well today  \n",
              "2                  what are you doing  \n",
              "3   I don't like anything this summer  \n",
              "4  The boy came wearing a white shirt  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f51dee58-450a-4cc5-adb1-cdacd5616f8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>banglish_speech</th>\n",
              "      <th>barishal_bangla_speech</th>\n",
              "      <th>barishal_banglish_speech</th>\n",
              "      <th>region_name</th>\n",
              "      <th>english_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো ?</td>\n",
              "      <td>kemon acho?</td>\n",
              "      <td>আসো কোরোহম?</td>\n",
              "      <td>Aso korohom?</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>How are you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে আমার মন ভালো নেই</td>\n",
              "      <td>ajke amr mon valo nei</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>aij mor monda valona</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>I'm not feeling well today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তুমি কি করো ?</td>\n",
              "      <td>tumi ki koro?</td>\n",
              "      <td>ও মোনু হর কি?</td>\n",
              "      <td>o monu horo ki?</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>what are you doing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>এই গরমে আমার কিছু ভালো লাগে না</td>\n",
              "      <td>ei gorome amar kichu valo lage na</td>\n",
              "      <td>এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>ei thada pora gorome mor kissu vallagena</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>I don't like anything this summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল</td>\n",
              "      <td>cheleti sada ronger ekti shirt pore eshechilo</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...</td>\n",
              "      <td>polaugga eukka dhola rong er eukka gunji poirr...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>The boy came wearing a white shirt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f51dee58-450a-4cc5-adb1-cdacd5616f8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f51dee58-450a-4cc5-adb1-cdacd5616f8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f51dee58-450a-4cc5-adb1-cdacd5616f8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38b99b13-112b-41ae-bd72-7edcebbb4583\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38b99b13-112b-41ae-bd72-7edcebbb4583')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38b99b13-112b-41ae-bd72-7edcebbb4583 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgix2qADvCY",
        "outputId": "adcafce8-cea1-4686-853b-d116f9b7d521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'barishal_bangla_speech ',\n",
              "       'barishal_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctg_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqtYoUU1D5Iu",
        "outputId": "e02cc0a7-8662-4885-b48e-d52b47d3eb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'chittagong_bangla_speech ',\n",
              "       'chittagong_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mymensingh_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU74zvbPD5F2",
        "outputId": "7589174b-f320-44a1-a91d-e496338de907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'mymensingh_bangla_speech ',\n",
              "       'mymensingh_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nohakhali_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDq4VG8hD5Cu",
        "outputId": "109f68fb-5e88-4ee6-d4a3-e597ae5e7fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'noakhali_bangla_speech ',\n",
              "       'noakhali_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8ALmdhlD_qb",
        "outputId": "00f581ab-ad75-4f4a-d953-07a1f8ebc539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'sylhet_bangla_speech ',\n",
              "       'sylhet_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Columns"
      ],
      "metadata": {
        "id": "9rAw9DZVIBK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.drop(columns=['banglish_speech ', 'barishal_bangla_speech ', 'english_speech'], inplace=True)\n",
        "ctg_train_df.drop(columns=['banglish_speech ', 'chittagong_bangla_speech ', 'english_speech'], inplace=True)\n",
        "mymensingh_train_df.drop(columns=['banglish_speech ', 'mymensingh_bangla_speech ', 'english_speech'], inplace=True)\n",
        "nohakhali_train_df.drop(columns=['banglish_speech ', 'noakhali_bangla_speech ', 'english_speech'], inplace=True)\n",
        "sylhet_train_df.drop(columns=['banglish_speech ', 'sylhet_bangla_speech ', 'english_speech'], inplace=True)\n"
      ],
      "metadata": {
        "id": "YtQLkxAVBp-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rename Columns from xyz_bangla_speech to regional_text"
      ],
      "metadata": {
        "id": "7_A0MzI6IFHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.rename(columns={'barishal_banglish_speech ': 'regional_text'}, inplace=True)\n",
        "ctg_train_df.rename(columns={'chittagong_banglish_speech ': 'regional_text'}, inplace=True)\n",
        "mymensingh_train_df.rename(columns={'mymensingh_banglish_speech ': 'regional_text'}, inplace=True)\n",
        "nohakhali_train_df.rename(columns={'noakhali_banglish_speech ': 'regional_text'}, inplace=True)\n",
        "sylhet_train_df.rename(columns={'sylhet_banglish_speech ': 'regional_text'}, inplace=True)"
      ],
      "metadata": {
        "id": "-ZqZXAPdGexC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Topj0NUC23p8",
        "outputId": "01aafc55-294d-4d81-82d8-6baded110ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'regional_text', 'region_name '], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSu3xJ7Y29a9",
        "outputId": "660a199f-3db4-4941-a538-aedc58ad7bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sylhet', 'Sylhet '], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '] = sylhet_train_df['region_name '].replace('Sylhet ', 'Sylhet')\n"
      ],
      "metadata": {
        "id": "Fjr5ZRtM3Lm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmBt8n_y3iZ4",
        "outputId": "031b6119-da68-4bf2-8a1d-e7eaca825a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sylhet'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concate all regional text"
      ],
      "metadata": {
        "id": "YyovFntJINYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([barishal_train_df, ctg_train_df, mymensingh_train_df, nohakhali_train_df, sylhet_train_df])"
      ],
      "metadata": {
        "id": "F34wOGtOBp7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.head(7000)"
      ],
      "metadata": {
        "id": "ga8EJ0e-Bp5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_Gp1klrjJAwj",
        "outputId": "95cc7acc-4fa2-4f3d-8531-e943764ca318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        bangla_speech   \\\n",
              "125                           সে সবসময় মিথ্যা কথা বলতো   \n",
              "126                             সবাই তাকে অনেক ভয় পেতো   \n",
              "127                             কেউ তাকে ভালোবাসতো নাহ   \n",
              "128                                  সে খুবই খারাপ ছিল   \n",
              "129  গ্রামের মানুষরা ছেলেটির থেকে দূরে থাকতে চেষ্টা...   \n",
              "..                                                 ...   \n",
              "370       তুমি কি আমাকে এক গ্লাস পানি এনে দিতে পারবে ?   \n",
              "371                            আমি পারবো না পানি দিতে    \n",
              "372                   তোমার ভাই পড়ালেখাতে অনেক মেধাবি    \n",
              "373               আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা?    \n",
              "374                 সামনের দিকে যেয়ে মেয়েটি অনেক হাসবে   \n",
              "\n",
              "                                         regional_text region_name   \n",
              "125                    he hokhol somoy micha mat matto       Sylhet  \n",
              "126                          hokhole tare khub doraito       Sylhet  \n",
              "127                             keu tare bala paito na       Sylhet  \n",
              "128                                 he bout bad achilo       Sylhet  \n",
              "129  gram or mainshe fuya ogur tone dure thakar che...       Sylhet  \n",
              "..                                                 ...          ...  \n",
              "370       tumi ki amare ek glass fani ene ditay farba?       Sylhet  \n",
              "371                             ami parbo na fani dite       Sylhet  \n",
              "372                tomar vai foralekhate bohut medhabi       Sylhet  \n",
              "373           aiccha kow dekhi bangladesho koyta jela?       Sylhet  \n",
              "374              samnor dike jaiya furita bohut hashbo       Sylhet  \n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e682993-5efc-4faa-ac65-7a0841a787c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>সে সবসময় মিথ্যা কথা বলতো</td>\n",
              "      <td>he hokhol somoy micha mat matto</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>সবাই তাকে অনেক ভয় পেতো</td>\n",
              "      <td>hokhole tare khub doraito</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>কেউ তাকে ভালোবাসতো নাহ</td>\n",
              "      <td>keu tare bala paito na</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>সে খুবই খারাপ ছিল</td>\n",
              "      <td>he bout bad achilo</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>গ্রামের মানুষরা ছেলেটির থেকে দূরে থাকতে চেষ্টা...</td>\n",
              "      <td>gram or mainshe fuya ogur tone dure thakar che...</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>তুমি কি আমাকে এক গ্লাস পানি এনে দিতে পারবে ?</td>\n",
              "      <td>tumi ki amare ek glass fani ene ditay farba?</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>আমি পারবো না পানি দিতে</td>\n",
              "      <td>ami parbo na fani dite</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>তোমার ভাই পড়ালেখাতে অনেক মেধাবি</td>\n",
              "      <td>tomar vai foralekhate bohut medhabi</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা?</td>\n",
              "      <td>aiccha kow dekhi bangladesho koyta jela?</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>সামনের দিকে যেয়ে মেয়েটি অনেক হাসবে</td>\n",
              "      <td>samnor dike jaiya furita bohut hashbo</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e682993-5efc-4faa-ac65-7a0841a787c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e682993-5efc-4faa-ac65-7a0841a787c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e682993-5efc-4faa-ac65-7a0841a787c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-017438d3-d764-4804-ba0b-dc176730c7ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-017438d3-d764-4804-ba0b-dc176730c7ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-017438d3-d764-4804-ba0b-dc176730c7ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode region_name column"
      ],
      "metadata": {
        "id": "FF0c56bDIgPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HHgsANNJNYa",
        "outputId": "3d48ef73-2b37-4a62-e21b-4c96bfbcfac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'regional_text', 'region_name '], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'bangla_speech ': 'bangla_speech'}, inplace=True)\n",
        "df.rename(columns={'region_name ': 'region_name'}, inplace=True)"
      ],
      "metadata": {
        "id": "LoeSXWm5RvkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['region_encoded'] = label_encoder.fit_transform(df['region_name'])"
      ],
      "metadata": {
        "id": "fbZs91_7Bp3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_name'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ6_TArJIy6Q",
        "outputId": "948496a3-e50d-480b-8d60-c18ce23e0583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Barishal ', 'Chittagong', 'Mymensingh', 'Noakhali', 'Sylhet'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_encoded'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFhhenUbJVoB",
        "outputId": "b933cfce-92e9-4271-cf92-a93a6881f93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.drop(columns=['region_name '], inplace=True)"
      ],
      "metadata": {
        "id": "nAWyh49dJieR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "jmYcIrA-KRxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('/content/drive/MyDrive/On going Research/VASHANTOR/combined_regional_text.csv', index=False)"
      ],
      "metadata": {
        "id": "69mMI0isi9hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Normalize"
      ],
      "metadata": {
        "id": "2af10LpEQeYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Puntuation**"
      ],
      "metadata": {
        "id": "F3iovqA0Ub-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations(text):\n",
        "  whitespace = re.compile(u\"[\\s\\u0020\\u00a0\\u1680\\u180e\\u202f\\u205f\\u3000\\u2000-\\u200d]+\", re.UNICODE)\n",
        "  bangla_fullstop = u\"\\u0964\"\n",
        "  text = re.sub(r'(^|\\s)@(\\w+)', r'\\1@user', text)\n",
        "  text = re.sub(r'\\bhttp?s://\\S+\\b', '', text)\n",
        "  punctSeq = u\"['\\\"“”‘’]+|[.?!,…]+|[:;]+\"\n",
        "  punc = u\"[(),$%^&*+={}\\[\\]:\\\"\\৷|\\'\\~`<>/,¦!?½£¶¼©⅐⅑⅒⅓⅔⅕⅖⅗⅘⅙⅚⅛⅜⅝⅞⅟↉¤¿º;-]+\"\n",
        "  text = whitespace.sub(\" \", text).strip()\n",
        "  text = re.sub(punctSeq, \" \", text)\n",
        "  text = re.sub(bangla_fullstop, \" \", text)\n",
        "  text = re.sub(punc, \" \", text)\n",
        "  text = re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]', ' ', text)\n",
        "  result = re.sub(r'\\b[a-zA-Z]+\\b', '', text)\n",
        "  text=text.replace(\"\\\\\", \" \")\n",
        "  normalized = normalize(text)\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "v3cVC2_zQhtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bangla_speech'] = df['bangla_speech'].apply(remove_punctuations)\n",
        "df['regional_text'] = df['regional_text'].apply(remove_punctuations)"
      ],
      "metadata": {
        "id": "Kng1G4QgT0Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis Data"
      ],
      "metadata": {
        "id": "MOD2qhPBKWyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "teitE7ePQhyG",
        "outputId": "e570ad76-1a5a-4297-dc8a-27112bdf759c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       bangla_speech  \\\n",
              "0                                         কেমন আছো     \n",
              "1                              আজকে আমার মন ভালো নেই   \n",
              "2                                      তুমি কি করো     \n",
              "3                     এই গরমে আমার কিছু ভালো লাগে না   \n",
              "4            ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল   \n",
              "5  মেয়েটি লাল রঙয়ের শাড়ি পরে আমার সাথে দেখা করতে ...   \n",
              "6                      ছেলেটি সিলেট থেকে ঢাকায় এসেছে   \n",
              "7     মেয়েটি সিলেট থেকে আসা এই ছেলেটিকে অনেক ভালবাসে   \n",
              "8          ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি   \n",
              "9  মেয়েটি তাঁর সব স্বপ্নের মধ্যে ছেলেটাকে কল্পনা করে   \n",
              "\n",
              "                                       regional_text region_name  \\\n",
              "0                                       Aso korohom    Barishal    \n",
              "1                               aij mor monda valona   Barishal    \n",
              "2                                    o monu horo ki    Barishal    \n",
              "3           ei thada pora gorome mor kissu vallagena   Barishal    \n",
              "4  polaugga eukka dhola rong er eukka gunji poirr...   Barishal    \n",
              "5  maiaugga lal runga shari poirra mor loge deha ...   Barishal    \n",
              "6                   polaugga sylhet dia dhaha aisele   Barishal    \n",
              "7   maiaugga sylhet dia awa polauggare akser valopay   Barishal    \n",
              "8  polaugga maiauggare ahono valopawar chohe dehenai   Barishal    \n",
              "9  maiaugga heyar shob hopponer moiddhe polauggar...   Barishal    \n",
              "\n",
              "   region_encoded  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  \n",
              "5               0  \n",
              "6               0  \n",
              "7               0  \n",
              "8               0  \n",
              "9               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d81ec77c-a924-4454-a124-0d6ac62fe468\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "      <th>region_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>Aso korohom</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে আমার মন ভালো নেই</td>\n",
              "      <td>aij mor monda valona</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তুমি কি করো</td>\n",
              "      <td>o monu horo ki</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>এই গরমে আমার কিছু ভালো লাগে না</td>\n",
              "      <td>ei thada pora gorome mor kissu vallagena</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল</td>\n",
              "      <td>polaugga eukka dhola rong er eukka gunji poirr...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>মেয়েটি লাল রঙয়ের শাড়ি পরে আমার সাথে দেখা করতে ...</td>\n",
              "      <td>maiaugga lal runga shari poirra mor loge deha ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ছেলেটি সিলেট থেকে ঢাকায় এসেছে</td>\n",
              "      <td>polaugga sylhet dia dhaha aisele</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>মেয়েটি সিলেট থেকে আসা এই ছেলেটিকে অনেক ভালবাসে</td>\n",
              "      <td>maiaugga sylhet dia awa polauggare akser valopay</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি</td>\n",
              "      <td>polaugga maiauggare ahono valopawar chohe dehenai</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>মেয়েটি তাঁর সব স্বপ্নের মধ্যে ছেলেটাকে কল্পনা করে</td>\n",
              "      <td>maiaugga heyar shob hopponer moiddhe polauggar...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d81ec77c-a924-4454-a124-0d6ac62fe468')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d81ec77c-a924-4454-a124-0d6ac62fe468 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d81ec77c-a924-4454-a124-0d6ac62fe468');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97b8b9a4-4961-46a9-bcd5-99a692ee1318\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97b8b9a4-4961-46a9-bcd5-99a692ee1318')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97b8b9a4-4961-46a9-bcd5-99a692ee1318 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Stopwords**"
      ],
      "metadata": {
        "id": "lJmwHybEUhN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('bengali'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcgEU08a6oz",
        "outputId": "2cc405b4-3256-4dd0-84a7-2c2f3d0939b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stop_words_remover(text):\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    without_stop_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    without_stop_word_text = ' '.join(without_stop_words)\n",
        "\n",
        "    return without_stop_word_text\n"
      ],
      "metadata": {
        "id": "3M-MpbxPa5i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bangla_speech'] = df['bangla_speech'].apply(stop_words_remover)\n",
        "df['regional_text'] = df['regional_text'].apply(stop_words_remover)"
      ],
      "metadata": {
        "id": "rOiSw2GaaUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gF9iPilzbgM-",
        "outputId": "5d950716-85d4-4c66-9288-38dcfe767034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               bangla_speech  \\\n",
              "0                                   কেমন আছো   \n",
              "1                               আজকে মন ভালো   \n",
              "2                                        করো   \n",
              "3                             গরমে ভালো লাগে   \n",
              "4             ছেলেটি সাদা রঙয়ের শার্ট এসেছিল   \n",
              "5          মেয়েটি লাল রঙয়ের শাড়ি সাথে এসেছিল   \n",
              "6                   ছেলেটি সিলেট ঢাকায় এসেছে   \n",
              "7          মেয়েটি সিলেট আসা ছেলেটিকে ভালবাসে   \n",
              "8  ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি   \n",
              "9            মেয়েটি স্বপ্নের ছেলেটাকে কল্পনা   \n",
              "\n",
              "                                       regional_text region_name  \\\n",
              "0                                        Aso korohom   Barishal    \n",
              "1                               aij mor monda valona   Barishal    \n",
              "2                                     o monu horo ki   Barishal    \n",
              "3           ei thada pora gorome mor kissu vallagena   Barishal    \n",
              "4  polaugga eukka dhola rong er eukka gunji poirr...   Barishal    \n",
              "5  maiaugga lal runga shari poirra mor loge deha ...   Barishal    \n",
              "6                   polaugga sylhet dia dhaha aisele   Barishal    \n",
              "7   maiaugga sylhet dia awa polauggare akser valopay   Barishal    \n",
              "8  polaugga maiauggare ahono valopawar chohe dehenai   Barishal    \n",
              "9  maiaugga heyar shob hopponer moiddhe polauggar...   Barishal    \n",
              "\n",
              "   region_encoded  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  \n",
              "5               0  \n",
              "6               0  \n",
              "7               0  \n",
              "8               0  \n",
              "9               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71b44d3d-36c6-4840-8fe9-1e2fa7efe0a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "      <th>region_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>Aso korohom</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে মন ভালো</td>\n",
              "      <td>aij mor monda valona</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>করো</td>\n",
              "      <td>o monu horo ki</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>গরমে ভালো লাগে</td>\n",
              "      <td>ei thada pora gorome mor kissu vallagena</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের শার্ট এসেছিল</td>\n",
              "      <td>polaugga eukka dhola rong er eukka gunji poirr...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>মেয়েটি লাল রঙয়ের শাড়ি সাথে এসেছিল</td>\n",
              "      <td>maiaugga lal runga shari poirra mor loge deha ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ছেলেটি সিলেট ঢাকায় এসেছে</td>\n",
              "      <td>polaugga sylhet dia dhaha aisele</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>মেয়েটি সিলেট আসা ছেলেটিকে ভালবাসে</td>\n",
              "      <td>maiaugga sylhet dia awa polauggare akser valopay</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি</td>\n",
              "      <td>polaugga maiauggare ahono valopawar chohe dehenai</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>মেয়েটি স্বপ্নের ছেলেটাকে কল্পনা</td>\n",
              "      <td>maiaugga heyar shob hopponer moiddhe polauggar...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b44d3d-36c6-4840-8fe9-1e2fa7efe0a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71b44d3d-36c6-4840-8fe9-1e2fa7efe0a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71b44d3d-36c6-4840-8fe9-1e2fa7efe0a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06d7c091-ef30-48d8-a882-7f9119174ea2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06d7c091-ef30-48d8-a882-7f9119174ea2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06d7c091-ef30-48d8-a882-7f9119174ea2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kt427H5KThU",
        "outputId": "fb2e77b7-765e-438a-c890-c6cc62006bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBvkw17O4Y8",
        "outputId": "83716e12-d083-4b70-c8b3-e0d08bdcb2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 12500 entries, 0 to 374\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   bangla_speech   12500 non-null  object\n",
            " 1   regional_text   12500 non-null  object\n",
            " 2   region_name     12500 non-null  object\n",
            " 3   region_encoded  12500 non-null  int64 \n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 488.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_name'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IogpvwGI11l7",
        "outputId": "20f53741-13d9-4fe1-df58-729d2954cd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Barishal      2500\n",
              "Chittagong    2500\n",
              "Mymensingh    2500\n",
              "Noakhali      2500\n",
              "Sylhet        2500\n",
              "Name: region_name, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJfgIOCPNJC",
        "outputId": "59b7f311-e639-4583-9efd-45b428f8feee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bangla_speech     0\n",
              "regional_text     0\n",
              "region_name       0\n",
              "region_encoded    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_regions = df['region_name'].value_counts()\n",
        "plt.figure(figsize=(6, 6))\n",
        "unique_regions.plot(kind='bar', color='skyblue')\n",
        "plt.title('Count of Unique Region Names')\n",
        "plt.xlabel('Region Name')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "ws2hUFRTKefk",
        "outputId": "ad88a804-7230-4ffe-955d-89178a78f6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAJeCAYAAABriHXpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmJ0lEQVR4nO3dd1QU5/s28GvpKs1CjQRQEBWwKxIsWCLW2KOJvRfAnijR2JVEjSV2Y8Hkq4nGqLEXsEVEjSj2WFGMSrEgahCEvd8/fJmfK9jRHeH6nLPnsM88O3vP7LJ77cwzMxoRERARERHpmYG+CyAiIiICGEqIiIhIJRhKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSojyiIyMDHz99ddwcnKCgYEBWrRooZc6NBoNxo4dq5fn/hDs2bMHGo0Ge/bs0XcpRKrDUEJ5yqVLl9CnTx+UKFECZmZmsLS0hJ+fH2bNmoXU1FR9lwcAmDdvHsLCwnJ9vkuXLsXUqVPRpk0bLF++HIMHD35uXxcXFzRt2jTHaUeOHIFGo3knNaqFi4sLNBqNcitUqBCqVauGn3/+Wd+lvVP+/v7QaDRo1qxZtmlXrlyBRqPBtGnT9FAZ0RNG+i6AKLds3rwZbdu2hampKTp37gwvLy+kp6dj//79+Oqrr3D69GksWrRI32Vi3rx5KFasGLp27Zqr8921axc++ugjzJgxI1fn+7pSU1NhZKT+j5YKFSpg6NChAICbN29i8eLF6NKlC9LS0tCrV6939ry1atVCamoqTExM3tlzvMymTZsQHR2NypUr660Gopyo/5OD6BXExsaiffv2cHZ2xq5du+Dg4KBMCwwMxMWLF7F582Y9VvjuJSYmwtraWt9lwMzMTN8lvJKPPvoIHTt2VO537doVJUqUwIwZM95pKDEwMNDrOvr4449x//59jBs3Dhs2bNBbHUQ54e4byhOmTJmCBw8eYMmSJTqBJIubmxsGDhyo3M/IyMCECRNQsmRJmJqawsXFBd988w3S0tJ0Hve88REuLi46WzrCwsKg0WgQGRmJIUOGwMbGBoUKFULLli2RlJSk87jTp09j7969yq4Df3//Fy7bw4cPMXToUDg5OcHU1BQeHh6YNm0asi7wnbXZfffu3Th9+rQy39wcs9C1a1eYm5vj+vXraNGiBczNzWFjY4Nhw4YhMzNTp29O62z//v2oWrUqzMzMULJkSSxcuBBjx46FRqNR+mQtR067jXKa5/Xr19G9e3fY2dnB1NQUnp6eWLp06Rsvo42NDUqXLo1Lly7ptGu1WsycOROenp4wMzODnZ0d+vTpg7t372brN3bsWDg6OqJgwYKoU6cOzpw5k+298rwxJb///jsqV66MAgUKoFixYujYsSOuX7+u0+d1XofnsbCwwODBg7Fx40YcPXr0hX3v3LmDYcOGwdvbG+bm5rC0tESjRo1w/PhxnX5Zy7R69WqMGzcOH330ESwsLNCmTRvcu3cPaWlpGDRoEGxtbWFubo5u3bpl+18DgP/973/KOihSpAjat2+Pa9eu6fS5cOECWrduDXt7e5iZmaF48eJo37497t2790rLT+rGLSWUJ2zcuBElSpTAJ5988kr9e/bsieXLl6NNmzYYOnQoDh06hNDQUJw9exbr1q174zqCg4NRuHBhjBkzBleuXMHMmTMRFBSEVatWAQBmzpyJ4OBgmJubY+TIkQAAOzu7585PRPDZZ59h9+7d6NGjBypUqIDt27fjq6++wvXr1zFjxgzY2Njgl19+waRJk/DgwQOEhoYCAMqUKfPGy5GTzMxMBAQEwMfHB9OmTUN4eDh++OEHlCxZEv369Xvu406ePIkGDRrAxsYGY8eORUZGBsaMGfPC5X6ZhIQEVK9eHRqNBkFBQbCxscHWrVvRo0cPpKSkYNCgQa89z4yMDPz7778oXLiwTnufPn0QFhaGbt26YcCAAYiNjcWcOXNw7NgxREZGwtjYGAAQEhKCKVOmoFmzZggICMDx48cREBCAR48evfS5s+ZftWpVhIaGIiEhAbNmzUJkZCSOHTumswXsTV+Hpw0cOBAzZszA2LFjX7i15PLly1i/fj3atm0LV1dXJCQkYOHChahduzbOnDkDR0dHnf6hoaEoUKAARowYgYsXL2L27NkwNjaGgYEB7t69i7Fjx+LgwYMICwuDq6srRo8erTx20qRJ+Pbbb/H555+jZ8+eSEpKwuzZs1GrVi1lHaSnpyMgIABpaWkIDg6Gvb09rl+/jk2bNiE5ORlWVlavtPykYkL0gbt3754AkObNm79S/5iYGAEgPXv21GkfNmyYAJBdu3YpbQBkzJgx2ebh7OwsXbp0Ue4vW7ZMAEj9+vVFq9Uq7YMHDxZDQ0NJTk5W2jw9PaV27dqvVOv69esFgEycOFGnvU2bNqLRaOTixYtKW+3atcXT0/OV5uvs7CxNmjTJcdrff/8tAGTZsmVKW5cuXQSAjB8/XqdvxYoVpXLlyjptz66zFi1aiJmZmVy9elVpO3PmjBgaGsrTH0GxsbHZnvd58+zRo4c4ODjIrVu3dPq1b99erKys5L///nveoovIk+Vv0KCBJCUlSVJSkpw8eVI6deokACQwMFDp99dffwkAWbFihc7jt23bptMeHx8vRkZG0qJFC51+Y8eOFQA675Xdu3cLANm9e7eIiKSnp4utra14eXlJamqq0m/Tpk0CQEaPHq20vc7rkJOn3yPjxo0TABIdHS0i/7f+p06dqvR/9OiRZGZm6swjNjZWTE1NdWrIWiYvLy9JT09X2r/44gvRaDTSqFEjnXn4+vqKs7Ozcv/KlStiaGgokyZN0ul38uRJMTIyUtqPHTsmAOT3339/6bLSh4m7b+iDl5KSAuDJZulXsWXLFgDAkCFDdNqzBj2+zdiT3r176+ySqFmzJjIzM3H16tU3mt+WLVtgaGiIAQMGZKtVRLB169Y3rvVN9O3bV+d+zZo1cfny5ef2z8zMxPbt29GiRQt8/PHHSnuZMmUQEBDwRjWICP744w80a9YMIoJbt24pt4CAANy7d++luyUAYMeOHbCxsYGNjQ28vb3xyy+/oFu3bpg6darS5/fff4eVlRU+/fRTneepXLkyzM3NsXv3bgBAREQEMjIy0L9/f53nCA4OfmkdR44cQWJiIvr3768z1qRJkyYoXbp0ju/H130dcjJw4EAULlwY48aNe24fU1NTGBg8+ZrIzMzE7du3YW5uDg8PjxzXcefOnZUtRwDg4+MDEUH37t11+vn4+ODatWvIyMgAAKxduxZarRaff/65znq2t7eHu7u7sp6ztoRs374d//3332stL30YGErog2dpaQkAuH///iv1v3r1KgwMDODm5qbTbm9vD2tr6zcOEAB0vngBKLsCnh1/8KquXr0KR0fHbIEra9fM29T6Mk+HK+DJAFYbGxudtsKFC79w2ZKSkpCamgp3d/ds0zw8PN6orqSkJCQnJ2PRokVKqMi6devWDcCTQb8v4+Pjg507d2Lbtm2YNm0arK2tcffuXZ2jYi5cuIB79+7B1tY223M9ePBAeZ6s1+HZ91SRIkWy7Q56VtZjc1ofpUuXzvYav8nrkBMrKysMGjQIGzZswLFjx3Lso9VqMWPGDLi7u8PU1BTFihWDjY0NTpw4keMYjmff/1khwsnJKVu7VqtV5nHhwgWICNzd3bOt57Nnzyrr2dXVFUOGDMHixYtRrFgxBAQEYO7cuRxPkodwTAl98CwtLeHo6IhTp0691uOe/dJ9Hc8bVGhoaJhju/z/QalqYWZm9tzztmT9An32CJHnLVtued7r8ey61mq1AICOHTuiS5cuOT6mXLlyL32+YsWKoX79+gCAgIAAlC5dGk2bNsWsWbOUrWharRa2trZYsWJFjvN4Nhy8D7n5OmSNLRk3bhxmzpyZbfrkyZPx7bffonv37pgwYQKKFCkCAwMDDBo0SHkdXqW2l/1faLVaaDQabN26Nce+5ubmyt8//PADunbtij///BM7duzAgAEDEBoaioMHD6J48eKvstikYgwllCc0bdoUixYtQlRUFHx9fV/Y19nZGVqtFhcuXNAZDJqQkIDk5GQ4OzsrbYULF0ZycrLO49PT03Hz5s03rvV1wpCzszPCw8Nx//59na0l//zzjzL9TTg7O+PMmTM5Tjt37txbzftpNjY2KFCgAC5cuPDc58mStUXh2fX97JYCGxsbWFhYIDMzUwkVuaFJkyaoXbs2Jk+ejD59+qBQoUIoWbIkwsPD4efnhwIFCjz3sVnr6uLFi3B1dVXab9++/dItGFmPPXfuHOrWrasz7dy5c7nyOjxP1taSsWPH5hjw1qxZgzp16mDJkiU67cnJyShWrFiu1VGyZEmICFxdXVGqVKmX9vf29oa3tzdGjRqFAwcOwM/PDwsWLMDEiRNzrSbSD+6+oTzh66+/RqFChdCzZ08kJCRkm37p0iXMmjULANC4cWMAyPbLcPr06QCefDllKVmyJPbt26fTb9GiRa98+GVOChUqlO2L93kaN26MzMxMzJkzR6d9xowZ0Gg0aNSo0RvV0LhxY/z7779Yv369TntaWhoWL14MW1tbVKpU6Y3m/TRDQ0MEBARg/fr1iIuLU9rPnj2L7du36/S1tLREsWLFsq3vefPmZZtn69at8ccff+S4dezpQ7Bf1/Dhw3H79m389NNPAIDPP/8cmZmZmDBhQra+GRkZyutYr149GBkZYf78+Tp9nn3dclKlShXY2tpiwYIFOofJbt26FWfPntV5P74LgwYNgrW1NcaPH59tmqGhYbatfL///nu2Q5XfVqtWrWBoaIhx48Zlez4Rwe3btwE8GT+WNQ4li7e3NwwMDHI8xJg+PNxSQnlCyZIlsXLlSrRr1w5lypTROaPrgQMH8Pvvvyvniihfvjy6dOmCRYsWITk5GbVr18bhw4exfPlytGjRAnXq1FHm27NnT/Tt2xetW7fGp59+iuPHj2P79u1v9SuxcuXKmD9/PiZOnAg3NzfY2tpm+4WcpVmzZqhTpw5GjhyJK1euoHz58tixYwf+/PNPDBo0CCVLlnyjGnr37o2lS5eibdu26N69OypWrIjbt29j1apVOHXqFH7++edcO+PouHHjsG3bNtSsWRP9+/dHRkYGZs+eDU9PT5w4cUKnb8+ePfHdd9+hZ8+eqFKlCvbt24fz589nm+d3332H3bt3w8fHB7169ULZsmVx584dHD16FOHh4bhz584b1dqoUSN4eXlh+vTpCAwMRO3atdGnTx+EhoYiJiYGDRo0gLGxMS5cuIDff/8ds2bNQps2bWBnZ4eBAwfihx9+wGeffYaGDRvi+PHj2Lp1K4oVK/bCrWPGxsb4/vvv0a1bN9SuXRtffPGFckiwi4vLCy8XkBusrKwwcODAHAe8Nm3aFOPHj0e3bt3wySef4OTJk1ixYgVKlCiRqzWULFkSEydOREhICK5cuYIWLVrAwsICsbGxWLduHXr37o1hw4Zh165dCAoKQtu2bVGqVClkZGTgl19+UYIq5QF6OuqH6J04f/689OrVS1xcXMTExEQsLCzEz89PZs+eLY8ePVL6PX78WMaNGyeurq5ibGwsTk5OEhISotNHRCQzM1OGDx8uxYoVk4IFC0pAQIBcvHjxuYcE//333zqPf/bwT5Enh482adJELCwsBMBLDw++f/++DB48WBwdHcXY2Fjc3d1l6tSpOocei7zeIcEiInfv3pXBgwcr68DS0lLq1KkjW7duzda3S5cuUqhQoWztY8aMkWc/RpDDYdR79+6VypUri4mJiZQoUUIWLFiQ42P/++8/6dGjh1hZWYmFhYV8/vnnkpiYmOM8ExISJDAwUJycnMTY2Fjs7e2lXr16smjRopcu+4sOiQ4LC8t2aPKiRYukcuXKUqBAAbGwsBBvb2/5+uuv5caNG0qfjIwM+fbbb8Xe3l4KFCggdevWlbNnz0rRokWlb9++Sr+c3hMiIqtWrZKKFSuKqampFClSRDp06CD//vuvTp/XeR1y8rz3yN27d8XKyirHQ4KHDh0qDg4OUqBAAfHz85OoqCipXbu2zvs2a5mePVT3ef8XWfUmJSXptP/xxx9So0YNKVSokBQqVEhKly4tgYGBcu7cORERuXz5snTv3l1KliwpZmZmUqRIEalTp46Eh4e/dNnpw6ARUdkIPCLKF8aOHZvj5vq8JDk5GYULF8bEiROVk+UR0fNxTAkRUS7I6WimrHFLL7uUABE9wTElRES5YNWqVQgLC0Pjxo1hbm6O/fv349dff0WDBg3g5+en7/KIPggMJUREuaBcuXIwMjLClClTkJKSogx+5WGqRK+OY0qIiIhIFTimhIiIiFSBoYSIiIhUgWNKXoFWq8WNGzdgYWHxVtdLISIiym9EBPfv34ejo6Ny1ennYSh5BTdu3Mh2lUsiIiJ6ddeuXXvpRRMZSl5B1oXQrl27BktLSz1XQ0RE9OFISUmBk5OTzkVFn4eh5BVk7bKxtLRkKCEiInoDrzL8gQNdiYiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFRhKiIiISBUYSoiIiEgVGEqIiIhIFfQaSkJDQ1G1alVYWFjA1tYWLVq0wLlz53T6+Pv7Q6PR6Nz69u2r0ycuLg5NmjRBwYIFYWtri6+++goZGRk6ffbs2YNKlSrB1NQUbm5uCAsLe9eLR0RERK9Br6Fk7969CAwMxMGDB7Fz5048fvwYDRo0wMOHD3X69erVCzdv3lRuU6ZMUaZlZmaiSZMmSE9Px4EDB7B8+XKEhYVh9OjRSp/Y2Fg0adIEderUQUxMDAYNGoSePXti+/bt721ZiYiI6MU0IiL6LiJLUlISbG1tsXfvXtSqVQvAky0lFSpUwMyZM3N8zNatW9G0aVPcuHEDdnZ2AIAFCxZg+PDhSEpKgomJCYYPH47Nmzfj1KlTyuPat2+P5ORkbNu27aV1paSkwMrKCvfu3YOlpeXbLygREVE+8TrfoaoaU3Lv3j0AQJEiRXTaV6xYgWLFisHLywshISH477//lGlRUVHw9vZWAgkABAQEICUlBadPn1b61K9fX2eeAQEBiIqKyrGOtLQ0pKSk6NyIiIjo3TLSdwFZtFotBg0aBD8/P3h5eSntX375JZydneHo6IgTJ05g+PDhOHfuHNauXQsAiI+P1wkkAJT78fHxL+yTkpKC1NRUFChQQGdaaGgoxo0bl+vL+CLfHbv1Xp8vt4yoWEzfJbwxrvP3j+v8/eM6f/+4zt+cakJJYGAgTp06hf379+u09+7dW/nb29sbDg4OqFevHi5duoSSJUu+k1pCQkIwZMgQ5X5KSgqcnJzeyXMRERHRE6rYfRMUFIRNmzZh9+7dKF68+Av7+vj4AAAuXrwIALC3t0dCQoJOn6z79vb2L+xjaWmZbSsJAJiamsLS0lLnRkRERO+WXkOJiCAoKAjr1q3Drl274Orq+tLHxMTEAAAcHBwAAL6+vjh58iQSExOVPjt37oSlpSXKli2r9ImIiNCZz86dO+Hr65tLS0JERERvS6+hJDAwEP/73/+wcuVKWFhYID4+HvHx8UhNTQUAXLp0CRMmTEB0dDSuXLmCDRs2oHPnzqhVqxbKlSsHAGjQoAHKli2LTp064fjx49i+fTtGjRqFwMBAmJqaAgD69u2Ly5cv4+uvv8Y///yDefPmYfXq1Rg8eLDelp2IiIh06TWUzJ8/H/fu3YO/vz8cHByU26pVqwAAJiYmCA8PR4MGDVC6dGkMHToUrVu3xsaNG5V5GBoaYtOmTTA0NISvry86duyIzp07Y/z48UofV1dXbN68GTt37kT58uXxww8/YPHixQgICHjvy0xEREQ50+tA15edIsXJyQl79+596XycnZ2xZcuWF/bx9/fHsWPHXqs+IiIien9UMdCViIiIiKGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVEGvoSQ0NBRVq1aFhYUFbG1t0aJFC5w7d06nz6NHjxAYGIiiRYvC3NwcrVu3RkJCgk6fuLg4NGnSBAULFoStrS2++uorZGRk6PTZs2cPKlWqBFNTU7i5uSEsLOxdLx4RERG9Br2Gkr179yIwMBAHDx7Ezp078fjxYzRo0AAPHz5U+gwePBgbN27E77//jr179+LGjRto1aqVMj0zMxNNmjRBeno6Dhw4gOXLlyMsLAyjR49W+sTGxqJJkyaoU6cOYmJiMGjQIPTs2RPbt29/r8tLREREz2ekzyfftm2bzv2wsDDY2toiOjoatWrVwr1797BkyRKsXLkSdevWBQAsW7YMZcqUwcGDB1G9enXs2LEDZ86cQXh4OOzs7FChQgVMmDABw4cPx9ixY2FiYoIFCxbA1dUVP/zwAwCgTJky2L9/P2bMmIGAgID3vtxERESUnarGlNy7dw8AUKRIEQBAdHQ0Hj9+jPr16yt9SpcujY8//hhRUVEAgKioKHh7e8POzk7pExAQgJSUFJw+fVrp8/Q8svpkzeNZaWlpSElJ0bkRERHRu6WaUKLVajFo0CD4+fnBy8sLABAfHw8TExNYW1vr9LWzs0N8fLzS5+lAkjU9a9qL+qSkpCA1NTVbLaGhobCyslJuTk5OubKMRERE9HyqCSWBgYE4deoUfvvtN32XgpCQENy7d0+5Xbt2Td8lERER5Xl6HVOSJSgoCJs2bcK+fftQvHhxpd3e3h7p6elITk7W2VqSkJAAe3t7pc/hw4d15pd1dM7TfZ49YichIQGWlpYoUKBAtnpMTU1hamqaK8tGREREr0avW0pEBEFBQVi3bh127doFV1dXnemVK1eGsbExIiIilLZz584hLi4Ovr6+AABfX1+cPHkSiYmJSp+dO3fC0tISZcuWVfo8PY+sPlnzICIiIv3T65aSwMBArFy5En/++ScsLCyUMSBWVlYoUKAArKys0KNHDwwZMgRFihSBpaUlgoOD4evri+rVqwMAGjRogLJly6JTp06YMmUK4uPjMWrUKAQGBipbO/r27Ys5c+bg66+/Rvfu3bFr1y6sXr0amzdv1tuyExERkS69bimZP38+7t27B39/fzg4OCi3VatWKX1mzJiBpk2bonXr1qhVqxbs7e2xdu1aZbqhoSE2bdoEQ0ND+Pr6omPHjujcuTPGjx+v9HF1dcXmzZuxc+dOlC9fHj/88AMWL17Mw4GJiIhURK9bSkTkpX3MzMwwd+5czJ0797l9nJ2dsWXLlhfOx9/fH8eOHXvtGomIiOj9UM3RN0RERJS/MZQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKug1lOzbtw/NmjWDo6MjNBoN1q9frzO9a9eu0Gg0OreGDRvq9Llz5w46dOgAS0tLWFtbo0ePHnjw4IFOnxMnTqBmzZowMzODk5MTpkyZ8q4XjYiIiF6TXkPJw4cPUb58ecydO/e5fRo2bIibN28qt19//VVneocOHXD69Gns3LkTmzZtwr59+9C7d29lekpKCho0aABnZ2dER0dj6tSpGDt2LBYtWvTOlouIiIhen5E+n7xRo0Zo1KjRC/uYmprC3t4+x2lnz57Ftm3b8Pfff6NKlSoAgNmzZ6Nx48aYNm0aHB0dsWLFCqSnp2Pp0qUwMTGBp6cnYmJiMH36dJ3wQkRERPql+jEle/bsga2tLTw8PNCvXz/cvn1bmRYVFQVra2slkABA/fr1YWBggEOHDil9atWqBRMTE6VPQEAAzp07h7t37+b4nGlpaUhJSdG5ERER0bul6lDSsGFD/Pzzz4iIiMD333+PvXv3olGjRsjMzAQAxMfHw9bWVucxRkZGKFKkCOLj45U+dnZ2On2y7mf1eVZoaCisrKyUm5OTU24vGhERET1Dr7tvXqZ9+/bK397e3ihXrhxKliyJPXv2oF69eu/seUNCQjBkyBDlfkpKCoMJERHRO6bqLSXPKlGiBIoVK4aLFy8CAOzt7ZGYmKjTJyMjA3fu3FHGodjb2yMhIUGnT9b9541VMTU1haWlpc6NiIiI3q0PKpT8+++/uH37NhwcHAAAvr6+SE5ORnR0tNJn165d0Gq18PHxUfrs27cPjx8/Vvrs3LkTHh4eKFy48PtdACIiInouvYaSBw8eICYmBjExMQCA2NhYxMTEIC4uDg8ePMBXX32FgwcP4sqVK4iIiEDz5s3h5uaGgIAAAECZMmXQsGFD9OrVC4cPH0ZkZCSCgoLQvn17ODo6AgC+/PJLmJiYoEePHjh9+jRWrVqFWbNm6eyeISIiIv3Tayg5cuQIKlasiIoVKwIAhgwZgooVK2L06NEwNDTEiRMn8Nlnn6FUqVLo0aMHKleujL/++gumpqbKPFasWIHSpUujXr16aNy4MWrUqKFzDhIrKyvs2LEDsbGxqFy5MoYOHYrRo0fzcGAiIiKV0etAV39/f4jIc6dv3779pfMoUqQIVq5c+cI+5cqVw19//fXa9REREdH780GNKSEiIqK8i6GEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVIGhhIiIiFSBoYSIiIhUgaGEiIiIVOGNQkmJEiVw+/btbO3JyckoUaLEWxdFRERE+c8bhZIrV64gMzMzW3taWhquX7/+1kURERFR/vNap5nfsGGD8vf27dthZWWl3M/MzERERARcXFxyrTgiIiLKP14rlLRo0QIAoNFo0KVLF51pxsbGcHFxwQ8//JBrxREREVH+8VqhRKvVAgBcXV3x999/o1ixYu+kKCIiIsp/3ugqwbGxsbldBxEREeVzbxRKACAiIgIRERFITExUtqBkWbp06VsXRkRERPnLG4WScePGYfz48ahSpQocHByg0Whyuy4iIiLKZ94olCxYsABhYWHo1KlTbtdDRERE+dQbnackPT0dn3zySW7XQkRERPnYG4WSnj17YuXKlbldCxEREeVjb7T75tGjR1i0aBHCw8NRrlw5GBsb60yfPn16rhRHRERE+ccbhZITJ06gQoUKAIBTp07pTOOgVyIiInoTbxRKdu/endt1EBERUT73RmNKiIiIiHLbG20pqVOnzgt30+zateuNCyIiIqL86Y1CSdZ4kiyPHz9GTEwMTp06le1CfURERESv4o1CyYwZM3JsHzt2LB48ePBWBREREVH+lKtjSjp27Mjr3hAREdEbydVQEhUVBTMzs9ycJREREeUTb7T7plWrVjr3RQQ3b97EkSNH8O233+ZKYURERJS/vFEosbKy0rlvYGAADw8PjB8/Hg0aNMiVwoiIiCh/eaNQsmzZstyug4iIiPK5NwolWaKjo3H27FkAgKenJypWrJgrRREREVH+80ahJDExEe3bt8eePXtgbW0NAEhOTkadOnXw22+/wcbGJjdrJCIionzgjY6+CQ4Oxv3793H69GncuXMHd+7cwalTp5CSkoIBAwbkdo1ERESUD7zRlpJt27YhPDwcZcqUUdrKli2LuXPncqArERERvZE32lKi1WphbGycrd3Y2BharfatiyIiIqL8541CSd26dTFw4EDcuHFDabt+/ToGDx6MevXq5VpxRERElH+8USiZM2cOUlJS4OLigpIlS6JkyZJwdXVFSkoKZs+ends1EhERUT7wRmNKnJyccPToUYSHh+Off/4BAJQpUwb169fP1eKIiIgo/3itLSW7du1C2bJlkZKSAo1Gg08//RTBwcEIDg5G1apV4enpib/++utd1UpERER52GuFkpkzZ6JXr16wtLTMNs3Kygp9+vTB9OnTc604IiIiyj9eK5QcP34cDRs2fO70Bg0aIDo6+q2LIiIiovzntUJJQkJCjocCZzEyMkJSUtJbF0VERET5z2uFko8++ginTp167vQTJ07AwcHhrYsiIiKi/Oe1Qknjxo3x7bff4tGjR9mmpaamYsyYMWjatGmuFUdERET5x2sdEjxq1CisXbsWpUqVQlBQEDw8PAAA//zzD+bOnYvMzEyMHDnynRRKREREedtrhRI7OzscOHAA/fr1Q0hICEQEAKDRaBAQEIC5c+fCzs7unRRKREREedtrnzzN2dkZW7Zswd27d3Hx4kWICNzd3VG4cOF3UR8RERHlE290RlcAKFy4MKpWrZqbtRAREVE+9kbXviEiIiLKbQwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCnoNJfv27UOzZs3g6OgIjUaD9evX60wXEYwePRoODg4oUKAA6tevjwsXLuj0uXPnDjp06ABLS0tYW1ujR48eePDggU6fEydOoGbNmjAzM4OTkxOmTJnyrheNiIiIXpNeQ8nDhw9Rvnx5zJ07N8fpU6ZMwY8//ogFCxbg0KFDKFSoEAICAvDo0SOlT4cOHXD69Gns3LkTmzZtwr59+9C7d29lekpKCho0aABnZ2dER0dj6tSpGDt2LBYtWvTOl4+IiIhenZE+n7xRo0Zo1KhRjtNEBDNnzsSoUaPQvHlzAMDPP/8MOzs7rF+/Hu3bt8fZs2exbds2/P3336hSpQoAYPbs2WjcuDGmTZsGR0dHrFixAunp6Vi6dClMTEzg6emJmJgYTJ8+XSe8EBERkX6pdkxJbGws4uPjUb9+faXNysoKPj4+iIqKAgBERUXB2tpaCSQAUL9+fRgYGODQoUNKn1q1asHExETpExAQgHPnzuHu3bs5PndaWhpSUlJ0bkRERPRuqTaUxMfHAwDs7Ox02u3s7JRp8fHxsLW11ZluZGSEIkWK6PTJaR5PP8ezQkNDYWVlpdycnJzefoGIiIjohVQbSvQpJCQE9+7dU27Xrl3Td0lERER5nmpDib29PQAgISFBpz0hIUGZZm9vj8TERJ3pGRkZuHPnjk6fnObx9HM8y9TUFJaWljo3IiIierdUG0pcXV1hb2+PiIgIpS0lJQWHDh2Cr68vAMDX1xfJycmIjo5W+uzatQtarRY+Pj5Kn3379uHx48dKn507d8LDwwOFCxd+T0tDREREL6PXUPLgwQPExMQgJiYGwJPBrTExMYiLi4NGo8GgQYMwceJEbNiwASdPnkTnzp3h6OiIFi1aAADKlCmDhg0bolevXjh8+DAiIyMRFBSE9u3bw9HREQDw5ZdfwsTEBD169MDp06exatUqzJo1C0OGDNHTUhMREVFO9HpI8JEjR1CnTh3lflZQ6NKlC8LCwvD111/j4cOH6N27N5KTk1GjRg1s27YNZmZmymNWrFiBoKAg1KtXDwYGBmjdujV+/PFHZbqVlRV27NiBwMBAVK5cGcWKFcPo0aN5ODAREZHK6DWU+Pv7Q0SeO12j0WD8+PEYP378c/sUKVIEK1eufOHzlCtXDn/99dcb10lERETvnmrHlBAREVH+wlBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqqDqUDJ27FhoNBqdW+nSpZXpjx49QmBgIIoWLQpzc3O0bt0aCQkJOvOIi4tDkyZNULBgQdja2uKrr75CRkbG+14UIiIiegkjfRfwMp6enggPD1fuGxn9X8mDBw/G5s2b8fvvv8PKygpBQUFo1aoVIiMjAQCZmZlo0qQJ7O3tceDAAdy8eROdO3eGsbExJk+e/N6XhYiIiJ5P9aHEyMgI9vb22drv3buHJUuWYOXKlahbty4AYNmyZShTpgwOHjyI6tWrY8eOHThz5gzCw8NhZ2eHChUqYMKECRg+fDjGjh0LExOT9704RERE9Byq3n0DABcuXICjoyNKlCiBDh06IC4uDgAQHR2Nx48fo379+krf0qVL4+OPP0ZUVBQAICoqCt7e3rCzs1P6BAQEICUlBadPn37uc6alpSElJUXnRkRERO+WqkOJj48PwsLCsG3bNsyfPx+xsbGoWbMm7t+/j/j4eJiYmMDa2lrnMXZ2doiPjwcAxMfH6wSSrOlZ054nNDQUVlZWys3JySl3F4yIiIiyUfXum0aNGil/lytXDj4+PnB2dsbq1atRoECBd/a8ISEhGDJkiHI/JSWFwYSIiOgdU/WWkmdZW1ujVKlSuHjxIuzt7ZGeno7k5GSdPgkJCcoYFHt7+2xH42Tdz2mcShZTU1NYWlrq3IiIiOjd+qBCyYMHD3Dp0iU4ODigcuXKMDY2RkREhDL93LlziIuLg6+vLwDA19cXJ0+eRGJiotJn586dsLS0RNmyZd97/URERPR8qt59M2zYMDRr1gzOzs64ceMGxowZA0NDQ3zxxRewsrJCjx49MGTIEBQpUgSWlpYIDg6Gr68vqlevDgBo0KABypYti06dOmHKlCmIj4/HqFGjEBgYCFNTUz0vHRERET1N1aHk33//xRdffIHbt2/DxsYGNWrUwMGDB2FjYwMAmDFjBgwMDNC6dWukpaUhICAA8+bNUx5vaGiITZs2oV+/fvD19UWhQoXQpUsXjB8/Xl+LRERERM+h6lDy22+/vXC6mZkZ5s6di7lz5z63j7OzM7Zs2ZLbpREREVEu+6DGlBAREVHexVBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqpCvQsncuXPh4uICMzMz+Pj44PDhw/ouiYiIiP6/fBNKVq1ahSFDhmDMmDE4evQoypcvj4CAACQmJuq7NCIiIkI+CiXTp09Hr1690K1bN5QtWxYLFixAwYIFsXTpUn2XRkRERACM9F3A+5Ceno7o6GiEhIQobQYGBqhfvz6ioqKy9U9LS0NaWppy/969ewCAlJSUd1bjowf339m836WUFBN9l/DGuM7fP67z94/r/P3jOn92vk++O0XkpX3zRSi5desWMjMzYWdnp9NuZ2eHf/75J1v/0NBQjBs3Llu7k5PTO6vxQ5V9LdG7xnX+/nGdv39c5+/fu17n9+/fh5WV1Qv75ItQ8rpCQkIwZMgQ5b5Wq8WdO3dQtGhRaDQaPVb2+lJSUuDk5IRr167B0tJS3+XkC1zn7x/X+fvHdf7+fajrXERw//59ODo6vrRvvgglxYoVg6GhIRISEnTaExISYG9vn62/qakpTE1Nddqsra3fZYnvnKWl5Qf1Js4LuM7fP67z94/r/P37ENf5y7aQZMkXA11NTExQuXJlREREKG1arRYRERHw9fXVY2VERESUJV9sKQGAIUOGoEuXLqhSpQqqVauGmTNn4uHDh+jWrZu+SyMiIiLko1DSrl07JCUlYfTo0YiPj0eFChWwbdu2bINf8xpTU1OMGTMm2+4oene4zt8/rvP3j+v8/csP61wjr3KMDhEREdE7li/GlBAREZH6MZQQERGRKjCUEBERkSowlBAREZEqMJQQERGRKjCUEH0AeJAc5TWJiYn6LiHPyszM1HcJb4yhhHTwy0+dsq65dPz4cT1XQvT2xo4di8mTJyM9PV3fpeQ5Dx8+hKGhIQDgzJkzePz4sZ4rej0MJaTj/Pnz+i6BnqLVapW/d+zYgc6dO2PlypV6rCh/et4vT4b4N1OuXDn06tULJiYmePjwob7LyTMiIiLQu3dvZGZmYsCAAfjyyy/x6NEjfZf1WhhKSLFz506UKVMGq1ev1ncphCeBxMDgyb/omjVrsGbNGly7dg2TJ0/Gb7/9pufq8ofbt28DgPLLc/78+fj6668xdOhQ3L9//4O7ari+RUdHIyMjA61atYKnpyd2796NwYMH4/Tp0/ouLU84ffo0YmNjUalSJaxYsQJ//PEHLCws9F3Wa2EoIUXJkiXRr18/9OvXD2vWrNF3OfleViAZPnw4BgwYgNKlS2PYsGEAgJkzZ+KXX37RZ3l53oABA1CtWjVcv34dADB69GiEhITg/Pnz+PXXX1G9enUcPXpUz1V+OP7880906tQJCxcuVLYAJiUlYfXq1Zg3bx7Onj2r5wo/fAMGDICDgwNOnjyJGjVqwNbWFoDuFlfVE6KnXL16VYKDg8XS0lJ+//13fZeT7509e1ZKlCghmzZtUtqio6OlTZs2UrFiRVm9erUeq8vbYmNjpUyZMlK9enU5f/68tGvXTo4cOSIiIg8ePBA/Pz8pWbKk0kYvdvv2bfn888+lZs2aMm/ePHn8+LGIiKxZs0aKFy8uffr0kTNnzui5yg+PVqsVEZH09HR5+PChTJ06VUaOHCm1atWSzp07y40bN0RElPWtdgwllM2VK1cYTFTi2rVrYm9vL7/99ptO+7Fjx6RYsWLi5eUlK1as0FN1eV9cXJy4u7tLmTJlxM/PTy5fvqxMS09PFz8/P3Fzc2MweYmMjAwREbl79658+eWX8sknn8icOXOUL8rVq1czmLyBzMxM5e/09HSd+/PmzRNfX1+dYCIicvjwYVUHFO6+oWycnZ0xcOBAdOnSBT169OCunPckp02sIgI7OzucPn0ajx8/VgZWVqhQAdWrV4elpSV++eUXREZGvu9y86ynB7U6OTkhIiIC1tbWOHz4MO7evQvgyWtlbGyM3bt3w9HREf7+/jh37py+SlY9Q0NDZGZmwtraGnPmzIGzszNWrlyJhQsXIiMjA23btsX06dOxefNmzJkzB6dOndJ3yar39JizadOmoUWLFvDy8kK/fv1w7tw59OvXDx07dsSVK1cwaNAgREdHo0GDBhgxYgSMjIz0XP0L6DsVkX5lbfq7ePGiHD9+XP7++29l2sWLF7nF5D15+hdOXFyc3Lp1S3ltfvzxRzEwMJAFCxbIf//9JyJPdh+0a9dOFi5cKKVKlZIJEybope687MiRI5KcnCwiT16TsmXLStWqVeXatWsiorvZvF+/fsrWAHq527dvS/v27bNtMVmzZo0ULFhQBg8eLGlpaXqu8sPwzTffiL29vcyaNUvCw8PFxMREmjRporx3Fy1aJDVq1BBHR0fx8/NT/XplKMnHsj5U161bJ2XLlhVnZ2cpW7asdOnSRelz6dIlCQ4OlqJFi8r//vc/PVWaf3z77bdSokQJKVeunLRt21b5sB43bpwYGhpK+/btpX///lKjRg2pUKGCiIh88cUX0qhRI+X1pDfzdDDct2+faDQamT9/vk4w8fDwEB8fn2zBJAuDia6s9XP58mU5ePCgxMbGyt27d0VE5NatWzkGk/Xr18v58+f1VfIH5fTp01K2bFnZtWuXiIgcPHhQTE1NZcmSJTr9/v33Xzly5IjyHlfz7huGknxu69atYm5uLvPnz5dr165JWFiYaDQaadeundLn8uXL0q1bN/n4448lJSVFj9XmPU9/Ea5evVpsbW1lxYoVMnHiRKlQoYJ4eXkpHyArVqyQbt26Sf369aV79+7y6NEjERFp3LixDB06VC/15xVPh4uZM2fK4sWLxdDQUIoUKSJz5sxR3vdxcXFSunRp+eSTT+TKlSv6KveDkLVO165dKyVKlBAXFxdxd3eXoKAgZdxIVjCpVauWTJs2TdVflmp09OhRKV++vIg8Wc9Zn+UiIikpKbJ+/fpsj1F7cGYoyceSkpKkffv2MnXqVBERuXHjhri4uEizZs2kaNGi0qpVK6VvbGysxMfH66vUPG/VqlWyZMkSWb58uYg8CSuHDh0ST09P8fT0lPT0dBERSU1NVR5z9+5dGTlypBQrVoyDA3PJmDFjpHDhwrJ27Vr55ZdfpE+fPmJkZJQtmFhbW0uvXr30XK36bd++XaysrGTWrFmSmZkp3333nfLZcvz4cRF5siunSZMmEhAQIHfu3NFzxeqV05bQS5cuiYuLi3z77bdiZWWlBBIRkaioKKlbt64cO3bsPVb59hhK8rHMzEyZP3++nD17VhITE8Xb21v69Okj6enp8t1334lGo5FGjRrpu8w87/z58+Lo6CgajUYWL16stGu1Wjl06JB4eXlJ+fLllWAi8iRABgcHi7Oz8wf3oaNWycnJUqFCBZk5c6ZOe0hIiBgZGcm8efOUXQ8JCQn8Vf8Sd+/elVatWsmYMWNEROTmzZvi4uIitWvXlooVK0rLli2VMH3nzh35999/9Vituj39v//gwQPlb61WK/3795cCBQpIcHCw0v7o0SNp2rSpNG/eXGdr7IeAoSSfeN4bM6t98eLF4u/vrxw6FhYWJn5+fuLp6SlXr159b3XmR//995+sXbtWypYtKzVq1NCZptVq5fDhw2JjYyOdO3fWaT9//rzExcW973LzJK1WK7du3RIXFxdlf/zTAwIbNGggRYsWlYULF+p8Qah9U7i+bd26VY4fPy63bt0ST09PZevSmDFjpGDBglK3bl1liwll99dff+mEkO+//16aN28uTZo0kd27d8vjx4/l+PHj0rhxY/Hw8JAJEybI5MmTpX79+uLl5aW8Vz+kYMJDgvO4e/fuAfi/a3QcPXoUYWFhiIqKwq1bt5RDys6cOYPExEQ4ODgAAM6ePYt69erhyJEj+Pjjj/VTfB707GG/jx8/RoECBdC0aVNMmTIF//77Lxo2bKhM12g0qFKlCvbt24elS5fqtLu7u8PJyem91Z6XPPs6aDQaFC1aFFWqVMHMmTPx4MEDmJiYICMjAyKCEiVKwNnZGUFBQcrh1yKinH4+v9NqtTleB8jf3x/lypXDH3/8ATs7O0yePBkA4O7uDnd3d9jb26NIkSLvu9wPwnfffYc2bdpg48aNAIAff/wRkydPhre3N27evInevXtj3rx58PT0xPfff4+2bdti6dKl2L9/P9zc3HDs2DEYGxsjIyND+Zz/IOg3E9G7tHjxYunWrZtcvHhRRET++OMPMTc3l1KlSomVlZX07dtXjh49KiIikZGRYm5uLv7+/tKqVSuxtLSU06dP67P8POfpXyuzZ8+Wbt26Se3atWXRokXK0RybNm0SNze35+424y/zt/f063D06FGJiYlRxjJER0dL1apVpWHDhsrh15mZmdK6dWs5evSofP7551KlShWdrSX5WdYurKzxDocPH5bVq1dnO4XAd999Jx4eHsqWveHDh8u4ceM4huQFtFqtNG/eXMqVKye//vqr9OrVS8LDw5Xp/fr1E09PT5k5c6ayNeX+/fs68/gQPy8YSvKwyZMni7e3twwYMEAOHTokLVu2lEWLFklaWposXrxY/Pz8pF27dsqYhI0bN8pnn30mXbp0kRMnTui3+Dzs66+/lqJFi0q/fv2kU6dOUqRIEenYsaPO61C6dGmpUqWKfgvN44YNGyaurq5iYmIiLVu2VI5U2Lhxo1SuXFns7OykZcuW4u3tLR4eHpKRkSHjxo2TTz75RM+Vq8PUqVOlTZs2yhfiunXrxMzMTLy9vcXAwEDatm2rjBNZu3atVK1aVWrXri3NmzeXggULcnD2c8yePVsOHDggIk+CSZMmTcTT01Pc3Nzk4MGDOn379+8vXl5eMmPGDElKStKZ9qGeIoChJI/78ccfpUqVKhIUFCQtW7aUhIQEZdrKlSuVYPJ0CFH7yXU+ZIcPHxZnZ2eJjIxU2rZs2SKVKlWSHj16SGpqqqSmpsqqVaukXbt2H9S+YDXTarU6H9Jbt24VDw8P2bVrl2zYsEEaNWoktWrVUk7nf/PmTRk1apT0799fRowYofxPdOvWTdq0aSOPHj36YD/0c8u2bdvE1NRUunfvLgkJCVKvXj1Zvny5JCYmyt9//y12dnbSoEED5ai9n376Sfr06SPt27eXU6dO6bl6ddq3b584OTlJt27ddE5k2aFDBzEwMJCpU6cqW/CyBAcHi62trfz666/vu9x3gqEkj3p6s92UKVOkZMmSUrRo0Wy/Tn799Vfx9/eXRo0a8SiO9+DQoUNSvHhxOXHihM6X2saNG8XExET2798vIronN2IweTtPH0Yt8iSQ9O/fX77//nul7Z9//pG2bdtKzZo15Zdffsk2j9u3b8vAgQOlcOHC3K35lN27d0uhQoWkQ4cO0q5dO2U3pMiTo8rs7Oykfv36kpiYqLTzqKUXW7FihVStWlW6du2qE0xatWolnp6esnLlymzv6R9++OGD3FWTE4aSPCjry+7pD4iFCxeKm5ub9OrVSxljkiUsLEwaNWrEQ/JyWU6/pA8cOCDm5uYSEREhIqKcAE1EpFSpUjJ37tz3Vl9+0KtXLyV8ZGZmSlxcnJQrV07MzMykX79+On2zgkndunVlzpw5SntcXJyEhoZK1apVGdwl+1an8PBwsbW1FTMzM+VHT1aQPn/+vBQvXlyqVav23LPg0hNPj1NatWqVVKxYMVsw+eyzz8Tb2zvHYCLyYY4heRZDSR6T9Q+/ceNGqVq1qs4mvVmzZknFihUlODhYLl26pPO4e/fuvdc687qnP3h//fVXnS+5zp07S9GiRXVOpX379m0pXbp0tqsB05tLT0/XOYQ3axfMoUOHxN/fX8qXLy+bNm3Secy5c+ekbt26EhgYqNMeGxubbZ99fhcREaGMfdi3b59YWVlJx44dlTEmWf8DZ8+eFQ8PD55a4BXFxMSIiMjPP/8slStXzhZMWrRoIRUqVJDFixfnyV3tDCV5xNOb+NeuXSsFCxaUH374QTm6JsuMGTOkfPnyMmjQILlw4cL7LjNfePq1OHnypFSsWFGqVq0qK1asEBGR69evS+PGjaVQoUIybdo0+fHHH6Vhw4ZSvnz5PPFLRw2e/TW+dOlS6dq1q3JW1qioKKlVq5Y0a9ZMtm7dqtM3Li5OeQ256+yJrFPqa7VaycjIkISEBHF3d5e9e/cqfXbt2iXm5ubSrVs3efjwoYj83/rj0UqvZtOmTVK4cGFlK8jzgkmNGjWkU6dO+irznWIo+cA9e+Kha9euiaenp8yePVtEnnwoZGRkSHh4uLKrYM6cOeLi4iLDhw/n/t13aNiwYdKmTRvx9fUVa2trKV26tDJeISUlRYYPHy5eXl5SvXp1adu2rfLBzWDy9rJCSdaX6PDhw6Vy5coyYMAAJZhERkY+N5iIMJBk2bx5s2g0Gp3DUTMyMsTDw0MOHz6sszsnK5j07NlT56Rf9GoyMzPFzc1NRowYobStWLFCKleuLN26dZMjR47o9M2LGEo+YPPmzZPPPvtMuYqpiMiJEyfEyclJLl68KGlpaTJlyhSpUaOGGBoaipeXl/KLZ+7cuXL58mV9lZ7nLV26VKytreXIkSPKKbTr168v1atX17naclJSkqSlpSkf6gyJb+/pD+vY2FgRebLrZtKkSVK9enUJCgpSgsmBAwekTp064uvrK1FRUfooV/WSkpKka9euOmOh7t69K25ubnL27Fml39PBRKPRZNsFRrqe3ZqXlpYmmZmZMmbMGGncuLFySQORJ8GkWrVq0rx5c511nheDCUPJB+zs2bPKoNWbN2+KyJNfMNWrVxc3NzdxcXGR5s2by6RJk+TWrVtSpEgR5ToU9G6FhIRIrVq1RKvVKh8ccXFxUrVqVSlVqpRy4b2ncQDg23v6Q3rcuHHi4+Mjhw4dEpEnH/oTJkwQHx8fnWCye/duCQwMzJMf8Lnl9u3b0rNnTzEzM5Pt27fL/fv3xcnJ6blXSt63b5/OlyfpenqQ6rPnhDp+/LiYmZlJWFiYTvtPP/0k3bt3z/PvU41IDucGJtXLzMxUTnH9999/46uvvkLfvn3Rvn17XLhwAStXroSlpSW++OILFCtWDEZGRmjZsiUaNGiAfv366bn6vEur1cLAwADjxo3D5s2b8ddff8HU1BSPHz+GsbExwsPD0bx5c3zyySfo06cP2rRpo++S86QRI0bg559/xqxZs1CtWjU4OzsDANLT0zFt2jT8+eefqF69OsaPHw8rKyvlcVmvH2V3584dDB8+HCtWrMCSJUswe/ZsFC9eHL6+vtBqtXj48CEAwMPDA+3atdNzteq1Y8cOxMTEoH79+oiNjcXQoUPh7e2Nb775BqVKlULRokUxcuRIHDlyBMuXL4etrW2292Refp/mzaXKB7LekLGxsXBzc0NGRgaWL1+OP//8E+7u7hgzZgwGDx4Me3t7pKWlYcyYMYiMjMSnn36q58rzlmevoZL1unz22WeIjo7GtGnTAADGxsYAnlzrpmHDhsjMzMRPP/2Ex48fv9+C84GoqCisWrUKq1evRtu2beHg4IDExERs374daWlpGDFiBFq2bIlNmzYp1xPK+m2WVz/oc0ORIkUwefJkdOjQAR06dMD169dRqFAhhIeHY8eOHdizZw8OHDgAT09PfZeqWsuWLUP37t1x5coVmJiYwMfHB4sXL8b9+/cRHByMhg0bYtu2bShevDgSExORlJQEAwMDZGRk6MwnT79P9bylht7C2rVrRaPRyNWrV+XMmTPy6aefyqeffqpz3YktW7ZIu3btpHjx4tmOxKG38+w1VLZv3y5Xr15VdgssXLhQjIyMJCQkRKKjo+Xy5cvSpEkTCQ0NlZMnT4pGo1H20VPu2bhxozg7O4uIyJEjR2TEiBFSqlQpMTExkYCAAElMTJRHjx7JsmXLOKj4ObJ2JV66dEnOnDmjM8AyISFBhgwZIkZGRsohwVl4lM3z/frrr1KwYEFZtWpVjqdg2L9/vwQHB4uLi4u0b99eNBqNtGrVKt+9RxlKPlBZp8HOOspGROT06dNKMFmzZo2IPDmteWhoqM45MejtPT3+Y8SIEeLu7i5FixaVatWqydChQ5UzWK5YsUKKFSsmxYsXl48++kgqVKggqampEhsbK+7u7rzG0FvKaf96UlKSWFtbS/ny5aVIkSLSq1cv+e233+TEiRNibGws69at0+mf3z70Xybrvb1+/XopXbq0uLu7i42NjQwePFg5L0bW4FcLCwvZsGFDtseSrsTERPH399c5X5HIkwvoRUZGypEjR5R1t3fvXlmyZIlUqlRJXFxclBP25Zd1y1DyAYqJiZFy5cqJl5eXREZGKoc9ioicOXNGGjRoIA0bNpTVq1eLCD9036XJkyeLg4OD7Nq1S0REunbtKsWKFZNu3brJjRs3ROTJESCRkZGyZ88e5Ut0xIgRUqZMGeW6IPT6ng4kUVFRcuLECSV8nz9/XkaNGiUbNmxQjk5LS0sTX19f2bJli17q/ZBs3bpVLCwsZP78+XLjxg35+eefRaPRSO/evZVDfe/cuSPt2rUTOzs75bwklLPExEQpW7asTiCeN2+etGnTRjQajTg6Ooqfn59O8Hj48KF4eHjI4MGD9VCx/jCUfIDCw8OlcePGYmZmppxfISMjQwkfZ8+eFR8fH2nRokW2S1nT23n6i/Cff/6R2rVrKx8027dvF3Nzc2nbtq14eHhIjx49lGCS5dSpU9KpUycpWrQoT1meS4YNGyYODg5ia2srfn5+2S5M9ujRI0lKSpLGjRtLlSpVGNJf4tatW9KhQwf57rvvROTJUWMlSpSQpk2birm5uXTp0kXZ/XD37t1s73HKLjExUYoXLy49e/aUiIgIad26tXh7e0u/fv1kx44d8vvvv0uJEiVkwoQJIvJ/l5+YNWuW1KlTJ1+FPoaSD9TevXulfv36UqJECeX8ClknShN5crpsntY5d+V0DpF169bJrVu3JDIyUuzt7WXBggUiItKuXTuxtraWzz77TDk9+ePHjyU6OloGDx4sJ0+efK+15yVP/5r8+++/xc3NTaKiomTt2rUSGBgoxYsXl6VLl4rIkzEOixcvFl9fX6levTpPUPcKUlNTZdGiRXL58mVJTEyUcuXKSa9evUREZPr06aLRaOTLL7/kydFeU3h4uFhZWUmJEiWkfPnyEhERIbdu3RKRJ1udKlSokO2UDe3btxdfX98cr3OTVxnpe6AtvZiIQKPR4ObNm9BqtdBqtXByckKtWrUQEhKC2bNnIzAwEPPnz0e1atWUPqVKldJ36XlKeHg4Hj58iObNm6Nnz564f/8+Vq1ahUaNGsHU1BSrVq1C48aN0b17dwCAm5sb4uLi4OHhgSJFigAAjIyMUKlSJXh7eytH49Dr02g0AJ4cyXD48GG0b98e1atXBwB4e3vDxMQE3377LQwNDdG5c2d4eXmhbdu2CA4OhpGRETIyMmBkxI++5zEzM0OHDh1QsGBBLFq0CFZWVhg3bhwAwMLCAtWqVUNkZCSSk5NRqFAhPVf74ahXrx4uXLiABw8ewNXVNdt0CwsLODo6AoByiHVCQgJmzpwJMzOz912u3vA/U8WyAsmGDRsQGhqK69evo1SpUqhfvz5GjBiBunXrQqvVYt68eQgKCsKMGTPg5+en77LzFBHB48ePMXr0aDx+/BjLly/H3r17sXv3bgCAqakpAODu3btISEhQzkdy7tw59OnTB507d4ZGo9E5rwADydu7ceMGNm3ahIiICHzxxRdKu5ubGwIDAwEAo0aNwqNHj9C7d2/4+PgAeHJ+HwaS/5P1GXPu3Dlcu3YN1tbW+Oijj+Dg4ACtVouzZ88iNTUVDg4OAIALFy6gffv26Nevn/Lep1dnY2MDGxsbnbakpCR069YN6enp6NGjB4Anh/xaWFhg+/bt+e/zQr8bauhlNm3aJIUKFZIZM2ZIZGSkjBw5UgwMDGTkyJFKn4iICKlbt67Url1bUlNT880o7ffh6V027u7uotFoZNasWUpb1hiT6dOnS5UqVaRGjRpSrVo1KVOmjLKLgK/H28tpHUZFRUn79u3FyspKNm7cqDPt4sWL0q1bN2nevDnX/3NkrZc1a9bIRx99JC4uLuLs7CylS5eWyMhIEXlyyngjIyNp3LixNG3aVKysrLjrMZckJSVJaGioNGnSRKpWrcpdi/8fQ4mKXbt2TerUqSM//vijiDx5Ezs5OUmNGjXE0tJSQkJClL579uyRa9eu6avUPG/Xrl1Sr149qVatmnzyySeybt06nQ+PzMxMmTVrlgQGBkpwcLASZvL7B0xueHpw8Y0bN+Sff/5R7v/zzz/yxRdfiKenp2zevFnncf/++6/yWAYT3fWY9f48dOiQWFhYyIIFC+Tff/+VPXv2SMeOHcXMzEz2798vIiJ//vmnNG3aVLp27cpD2HPRsWPHpGnTpjJw4EDl9eC1rxhKVOF51zJITU2VMWPGyKVLl+TGjRtSpkwZ6du3ryQlJUmnTp1Eo9HIoEGD3nO1+cPatWuVow8GDhwoffv2lUePHklGRob4+/uLj4+PrF+//oUfIvyAeXtPh4nRo0dLpUqVxM7OTnx9fWXOnDmSlpYmR48elY4dO4qXlxev9vsSV65cUdZpRkaGLF68WOrUqaOzjm7evClffvmlVKxYUTnfzuPHj/l+fgfu3r2r83oQQ4neZX0YXL16VVatWiWzZs3SGWmddbKiSZMmSbNmzZTR2hMnTpQyZcqIh4eH3Lx5k78Ec9GDBw9kwoQJYmxsLPXq1ZOCBQvq/EJMSUkRf39/+eSTT2T16tWSkpIiNWrUUI5Q4GuR+yZOnCi2trby559/ysOHD8XPz09Kliwpp0+fFpEnR+F07txZbGxseLXf53j06JFUr15dXFxclPfo9OnTpXDhwsoVabPaN23aJMWLF5czZ87oq9x8hZ8Z/4ehRI+yAsnx48fF1dVVKlWqJNbW1lK6dGn577//dPp+/vnnEhAQoNwfPHiwTJ06VTmlOb29Ll26KOcDSE1NlWrVqolGo5EhQ4YofbLOH5CSkiIBAQFSunRpcXNzkwoVKigBknKPVquV27dvS82aNZXzj4SHh4u5ubksWrRIRP7v/ygqKkrGjRvHX5zPodVq5a+//hIvLy+pUKGCaLVauXTpkpQtW1amT5+uBBORJ6cUKFGihHKFZaL3haFET7I+SGNiYqRAgQIycuRIiY+PlwsXLkjx4sWVs7Fm+emnn6R48eLSr18/6dmzpxQuXJinjs9Fly5dktatWyuhIy0tTQYMGCD9+/cXKysr+f7775W+WYHx4cOHsm7dOlm2bBn3Cb9Dt2/flgoVKkhycrJs3bpVzM3NZf78+SLy5LX46aef5PLlyzqPYTDJebdVZmamREVFiYeHh1StWlVEREaOHCne3t4yZcoUiY+Pl/v378vw4cPFzc1NEhIS3nfZlM8xlOjRhQsXxMzMTEaNGqXT7ufnJyNHjpQuXbrIypUr5caNG3Lnzh2ZNGmSVK1aVT799FOJiYnRU9V536JFi5QzVmatd0tLS2WMSZZnN23zi/DtPW8zdsWKFSUgIEAsLS3lp59+UtovX74stWvXlj/++ON9lfhByAokN2/ezLY7Kz09XQ4dOiSurq5Sq1YtERH59ttvxcvLS8zMzKR69epiY2PDC3iSXjCU6ElmZqaEhISIjY2NzJgxQ2kPDQ0VAwMD+eKLL8THx0eMjY1l0KBByhdeRkYGz6T4DiUmJspHH30kZcuWVXaN3bx5UyZPnixWVlYyYcIESU1NlcaNG0vPnj31XG3e8vQv+7i4OElJSdE5bNXJyUkaNmyo9Hn48KE0btxY6taty0CYg7i4OClatKhoNBrx9/eXkJAQiYiIUAL34cOHxdvbW/z8/ETkyft8yZIlsnbtWrly5Yo+S6d8TCMiou9zpeRXN27cwJQpU3Dw4EF07doVKSkpmDZtGn7++WcEBARAo9EgODgYYWFhOHnyJFxcXPRdcp4j///kUU/fP3XqFDp37gytVov9+/fDwsIC8fHxWLlyJUaMGAFXV1cYGxvj2LFj+e/ERu/BqFGjsHHjRty9exeDBg1Cq1at4ODggO+//x6zZs1ChQoVYGNjgxs3biA5ORnR0dEwNjZGZmYmDA0N9V2+aly9ehUtWrRAamoqLCws4OnpiVWrVqF06dLw9vZG06ZNodFoEBISghIlSmD79u06/wtE+sBQomfx8fGYNGkSdu7ciYsXL2LHjh2oW7cuUlNTUaBAAWzZsgXBwcHYsmULPDw89F1unvL0WVbv3r0LAChcuDAA4MyZM2jXrh0MDAyUYPLo0SNcvnwZZ86cQcuWLWFoaMhTluey33//HcOGDcPUqVMRGRmJnTt3ws/PD9988w0+/vhj7N+/H/Pnz0exYsXg5OSEoUOH8tTxL3Dx4kV8/fXX0Gq1CAkJgYODAw4cOIA5c+bg8ePHOHXqFEqWLIlTp06hefPmWLduXbagTvQ+MZSoQEJCAiZPnow9e/agc+fOGDp0qDJt0KBBOHjwILZu3ap8YdLbWbt2Lfz9/ZVr0owePRq7du3C9evXMXToUHz55ZcoUqSIEkwMDQ3x119/wcLCQmc+/GX+9p4OhsCTUHLlyhV89dVXAICwsDDMnj0bFSpUwLBhw1CmTJls8+Dr8GLnzp3DwIEDodVqMWnSJFStWhUAkJycjI0bN+Kff/7B1q1bsWTJElSsWFHP1VK+p7cdR6Tj5s2bEhQUJD4+PsqAygkTJoi5ubkcP35cz9XlHZs2bRKNRiOTJ0+WR48eyfz588Xe3l5mzJghgwYNEmNjYxk4cKBydtzTp09L+fLlxcHBIV9dPvx9eHpQ608//SQjRoyQzz//XGeMlYjIsmXLpHLlytKrVy85cuRIjo+nFzt//rwEBARIQECA7NmzJ9t0HjVGasFQoiJZwaRmzZpSrVo1MTMz0/kQptyxYMEC0Wg0MnPmTBk9erSsX79emfbbb7+JpaWlDBgwQP79918ReXIemU6dOnEwZS56elDrN998I+bm5lKrVi0pWLCglC5dWg4fPqzTf/ny5eLk5CShoaHvu9Q84/z589KwYUMJCAhQrm1DpDYMJSpz8+ZN6datm7i5ucmxY8f0XU6eEh0dLevWrZOrV6/KsmXLRKPRSKFChWTlypU6/X777TexsrKSQYMGZTsKgcEkd506dUoGDBignKRr7dq1UrduXfnss8+yBfItW7Zw/b+l8+fPS9OmTaV69eo88y2pEkOJCiUmJkp8fLy+y8hT/ve//0mFChWkSZMmyoUMlyxZIhqNRgYMGCB37tzR6b969WrRaDTZdiXQ23l6l8uaNWvE0dFRypUrJ9evX1fa//jjD6lfv740bdo0xy2FDCZv5+zZs9KmTRu5evWqvkshyoYDXSnP+/nnn9G3b18sXboUDRs2hLW1tTJt7ty5CA4OxuTJk9GvXz9YWVkp03bt2oVatWrxqI5cIk8d1ZGZmYlDhw7hu+++Q0REBCIiIlC9enWl77p167Bw4UKkpKRg6dKlKF26tL7KzpPS09NhYmKi7zKIsuGnLeVpp0+fxpQpU/Djjz+iffv2SnvWIaSBgYHIzMzEoEGDAAD9+/eHpaUlAKBu3bo6fentZAWSZcuW4erVqxg7diyGDRuG9PR09O7dGz/99BN8fHwAAC1btkRqaioOHz6MUqVK6bPsPImBhNTK4OVdiD5c169fx3///YdatWrh6Y2CRkZG0Gq1EBEMGDAA8+bNwzfffIPvvvsODx8+1JkHA0nuERHs2bMHW7duBQDUqlULw4cPh5ubG/r164fDhw8rfb/88kvMnDkTBgYG0Gq1+iqZiN4jhhLK06Kjo3H//n2UKlUKGo1GJ5gYGBhAo9HgzJkzaNSoEebMmYO9e/eiYMGCeqw4b3k6TGi1Wmg0GkyePBlXr17F/PnzAQB16tTBgAED4OLigsDAQOzfvz/bfJ4+lwkR5V38T6c8zc3NDQ8fPsSOHTsAIMczVYaFhWHSpEno378/9u/fny280Jt7Okxk/V24cGF89tlnOHjwIDIzMwEA/v7+GDhwIAoWLIilS5fqpVYi0j+GEsrTKleuDBMTEyxatAhxcXFKe1boSElJweXLl+Hp6akzjafZfjs7duzAb7/9BuDJYOLAwECcO3cOmZmZKFiwIJo3b45ff/0VBw4cUB5Tu3ZtzJw5E4sXL9ZX2USkZzz6hvK83377DV27dkXr1q0xbNgw5VTaN27cQM+ePZGSkoI9e/Zw7EguiYyMRM2aNVGpUiV0794dhoaGmDp1KooVKwZbW1t8//33cHV1RUhICG7duoX58+ejYMGCOltVnj39PBHlD/wUpjyvbdu2ePDgAfr37499+/bBy8sLWq0W9+7dg1arRWRkJIyMjHgNlVxy69YtAEChQoWwZ88edOjQARcuXMCff/6JBQsWoFGjRqhatSru3LmDx48f48GDBzA3N9cJIgwkRPkTt5RQvhETE4OlS5fi3LlzcHJyQsWKFdG3b19e7fcd6Ny5M65evYpixYohMTERAwcORJs2bQA8ueje2bNnMWPGDNy7dw/9+vXD3Llz9VwxEakBQwnle9xCknvS0tJgamqKFStWYO/evejRowemTJmCpKQk9OjRA126dFH6Xr58GXPmzEFMTAxWrVoFGxsbPVZORGrAbaSUr+SUwRlI3s7u3buxZMkSAICpqSmAJyee27JlC86cOYO5c+fCxsYGYWFh+N///qc8rkSJEggKCsLhw4exe/duvdROROrCUEL5Co+qyV27d+9GvXr10KtXLzRs2BALFizAqVOn4ODggGnTpmHdunUwNzfHhAkTULRoUYSFheGnn34C8GQwa4kSJVC9enUkJCToeUmISA0YSojojTk5OaFmzZqoU6cO0tLScObMGfj7+2PWrFm4efMmHj58iJiYGJQtWxbjx49HZmYmTpw4AeDJYNaVK1di165dCAgI0POSEJEacEwJEb2V8+fPIyQkBI8fP8aAAQOQmZmJRYsWITU1Fdu2bUPz5s2xZs0aGBoa4sqVK/j444+Vo2uSk5ORlJQEd3d3PS8FEakBQwkRvbVz585h0KBB0Gq1mDVrFtzd3XHu3DlMnz4dwcHBKF++vM5J6bKuO8TxPET0NIYSIsoVFy5cQFBQEABg1KhRqFmzpjKNJ0MjolfBTwkiyhXu7u6YM2cODAwMMHnyZJ0L6zGQENGr4CcFEeUad3d3/PjjjzA0NMTgwYOVQa1ERK+CoYSIcpW7uzumTp2KWrVqwcvLS9/lENEHhGNKiOid4ngSInpVDCVERESkCvz5QkRERKrAUEJERESqwFBCREREqsBQQkRERKrAUEJERESqwFBCREREqsBQQkR6ERYWBmtra32XQUQqwlBCRDq6du0KjUYDjUYDY2NjuLq64uuvv8ajR49y9XnatWuH8+fP5+o8c+Lv7w+NRoPffvtNp33mzJlwcXF5589PRK+OoYSIsmnYsCFu3ryJy5cvY8aMGVi4cCHGjBmTq89RoEAB2Nra5uo8n8fMzAyjRo3C48eP38vzEdGbYSghomxMTU1hb28PJycntGjRAvXr18fOnTuV6VqtFqGhoXB1dUWBAgVQvnx5rFmzRmceGzZsgLu7O8zMzFCnTh0sX74cGo0GycnJAHLefTN//nyULFkSJiYm8PDwwC+//KIzXaPRYPHixWjZsiUKFiwId3d3bNiw4aXL88UXXyA5ORk//fTTc/tcunQJzZs3h52dHczNzVG1alWEh4fr9HFxccHEiRPRuXNnmJubw9nZGRs2bEBSUhKaN28Oc3NzlCtXDkeOHNF53P79+1GzZk0UKFAATk5OGDBgAB4+fPjSuonyG4YSInqhU6dO4cCBAzAxMVHaQkND8fPPP2PBggU4ffo0Bg8ejI4dO2Lv3r0AgNjYWLRp0wYtWrTA8ePH0adPH4wcOfKFz7Nu3ToMHDgQQ4cOxalTp9CnTx9069YNu3fv1uk3btw4fP755zhx4gQaN26MDh064M6dOy+ct6WlJUaOHInx48c/Nww8ePAAjRs3RkREBI4dO4aGDRuiWbNmiIuL0+k3Y8YM+Pn54dixY2jSpAk6deqEzp07o2PHjjh69ChKliyJzp07I+sKHpcuXULDhg3RunVrnDhxAqtWrcL+/fsRFBT0wpqJ8iUhInpKly5dxNDQUAoVKiSmpqYCQAwMDGTNmjUiIvLo0SMpWLCgHDhwQOdxPXr0kC+++EJERIYPHy5eXl4600eOHCkA5O7duyIismzZMrGyslKmf/LJJ9KrVy+dx7Rt21YaN26s3Acgo0aNUu4/ePBAAMjWrVufuzy1a9eWgQMHyqNHj8TZ2VnGjx8vIiIzZswQZ2fnF64LT09PmT17tnLf2dlZOnbsqNy/efOmAJBvv/1WaYuKihIAcvPmTRF5sl569+6tM9+//vpLDAwMJDU19YXPT5TfcEsJEWVTp04dxMTE4NChQ+jSpQu6deuG1q1bAwAuXryI//77D59++inMzc2V288//4xLly4BAM6dO4eqVavqzLNatWovfM6zZ8/Cz89Pp83Pzw9nz57VaStXrpzyd6FChWBpaYnExMSXLpOpqSnGjx+PadOm4datW9mmP3jwAMOGDUOZMmVgbW0Nc3NznD17NtuWkqef387ODgDg7e2drS2rpuPHjyMsLExnXQUEBECr1SI2NvaldRPlJ0b6LoCI1KdQoUJwc3MDACxduhTly5fHkiVL0KNHDzx48AAAsHnzZnz00Uc6jzM1NX3ntRkbG+vc12g00Gq1r/TYjh07Ytq0aZg4cWK2I2+GDRuGnTt3Ytq0aXBzc0OBAgXQpk0bpKenP/f5NRrNc9uyanrw4AH69OmDAQMGZKvn448/fqW6ifILhhIieiEDAwN88803GDJkCL788kuULVsWpqamiIuLQ+3atXN8jIeHB7Zs2aLT9vfff7/wecqUKYPIyEh06dJFaYuMjETZsmXffiH+PwMDA4SGhqJVq1bo16+fzrTIyEh07doVLVu2BPAkTFy5cuWtn7NSpUo4c+aMEvKI6Pm4+4aIXqpt27YwNDTE3LlzYWFhgWHDhmHw4MFYvnw5Ll26hKNHj2L27NlYvnw5AKBPnz74559/MHz4cJw/fx6rV69GWFgYgP/bkvCsr776CmFhYZg/fz4uXLiA6dOnY+3atRg2bFiuLkuTJk3g4+ODhQsX6rS7u7tj7dq1iImJwfHjx/Hll1++8haYFxk+fDgOHDiAoKAgxMTE4MKFC/jzzz850JUoBwwlRPRSRkZGCAoKwpQpU/Dw4UNMmDAB3377LUJDQ1GmTBk0bNgQmzdvhqurKwDA1dUVa9aswdq1a1GuXDnMnz9fOfrmebt4WrRogVmzZmHatGnw9PTEwoULsWzZMvj7++f68nz//ffZTgY3ffp0FC5cGJ988gmaNWuGgIAAVKpU6a2fq1y5cti7dy/Onz+PmjVromLFihg9ejQcHR3fet5EeY1G5P8ft0ZE9A5NmjQJCxYswLVr1/RdChGpFMeUENE7MW/ePFStWhVFixZFZGQkpk6dyl0WRPRCDCVE9E5cuHABEydOxJ07d/Dxxx9j6NChCAkJ0XdZRKRi3H1DREREqsCBrkRERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAoMJURERKQKDCVERESkCgwlREREpAr/D8DTE+R/yGn6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To implement model"
      ],
      "metadata": {
        "id": "Cgxrr7r4Ah9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'regional_text': 'Data'}, inplace=True)\n",
        "df.rename(columns={'region_encoded': 'Label'}, inplace=True)"
      ],
      "metadata": {
        "id": "rWpqu261AhoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "jMhYMjyQAvC8",
        "outputId": "2294edca-24e7-4476-bf2a-3bd3c0b7b8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  bangla_speech         Data region_name  Label\n",
              "0      কেমন আছো  Aso korohom   Barishal       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f5c163c-0ee2-4ad1-9ff8-f1670ca8ddbf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>Data</th>\n",
              "      <th>region_name</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>Aso korohom</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f5c163c-0ee2-4ad1-9ff8-f1670ca8ddbf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f5c163c-0ee2-4ad1-9ff8-f1670ca8ddbf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f5c163c-0ee2-4ad1-9ff8-f1670ca8ddbf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Barishal', 'Chittagong','Mymensingh','Noakhali','Sylhet']"
      ],
      "metadata": {
        "id": "hr-dOVft7mto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "0g8VNA7mcwvb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "52f6439d-4320-4c45-cc8a-69c947463675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          bangla_speech  \\\n",
              "0                              কেমন আছো   \n",
              "1                          আজকে মন ভালো   \n",
              "2                                   করো   \n",
              "3                        গরমে ভালো লাগে   \n",
              "4        ছেলেটি সাদা রঙয়ের শার্ট এসেছিল   \n",
              "..                                  ...   \n",
              "370             এক গ্লাস পানি এনে পারবে   \n",
              "371                          পারবো পানি   \n",
              "372                ভাই পড়ালেখাতে মেধাবি   \n",
              "373  আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা   \n",
              "374            সামনের যেয়ে মেয়েটি হাসবে   \n",
              "\n",
              "                                                  Data region_name  Label  \n",
              "0                                          Aso korohom   Barishal       0  \n",
              "1                                 aij mor monda valona   Barishal       0  \n",
              "2                                       o monu horo ki   Barishal       0  \n",
              "3             ei thada pora gorome mor kissu vallagena   Barishal       0  \n",
              "4    polaugga eukka dhola rong er eukka gunji poirr...   Barishal       0  \n",
              "..                                                 ...         ...    ...  \n",
              "370        tumi ki amare ek glass fani ene ditay farba      Sylhet      4  \n",
              "371                             ami parbo na fani dite      Sylhet      4  \n",
              "372                tomar vai foralekhate bohut medhabi      Sylhet      4  \n",
              "373            aiccha kow dekhi bangladesho koyta jela      Sylhet      4  \n",
              "374              samnor dike jaiya furita bohut hashbo      Sylhet      4  \n",
              "\n",
              "[12500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b4e1fa8-10f4-4945-a899-e578dd97ceb2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>Data</th>\n",
              "      <th>region_name</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>Aso korohom</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে মন ভালো</td>\n",
              "      <td>aij mor monda valona</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>করো</td>\n",
              "      <td>o monu horo ki</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>গরমে ভালো লাগে</td>\n",
              "      <td>ei thada pora gorome mor kissu vallagena</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের শার্ট এসেছিল</td>\n",
              "      <td>polaugga eukka dhola rong er eukka gunji poirr...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>এক গ্লাস পানি এনে পারবে</td>\n",
              "      <td>tumi ki amare ek glass fani ene ditay farba</td>\n",
              "      <td>Sylhet</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>পারবো পানি</td>\n",
              "      <td>ami parbo na fani dite</td>\n",
              "      <td>Sylhet</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>ভাই পড়ালেখাতে মেধাবি</td>\n",
              "      <td>tomar vai foralekhate bohut medhabi</td>\n",
              "      <td>Sylhet</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা</td>\n",
              "      <td>aiccha kow dekhi bangladesho koyta jela</td>\n",
              "      <td>Sylhet</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>সামনের যেয়ে মেয়েটি হাসবে</td>\n",
              "      <td>samnor dike jaiya furita bohut hashbo</td>\n",
              "      <td>Sylhet</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b4e1fa8-10f4-4945-a899-e578dd97ceb2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b4e1fa8-10f4-4945-a899-e578dd97ceb2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b4e1fa8-10f4-4945-a899-e578dd97ceb2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7266d7e-3bd3-4771-a505-b7b44585a14f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7266d7e-3bd3-4771-a505-b7b44585a14f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7266d7e-3bd3-4771-a505-b7b44585a14f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_23eb42f6-df77-4800-93dd-89a19c7200f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_23eb42f6-df77-4800-93dd-89a19c7200f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Valid-Test"
      ],
      "metadata": {
        "id": "ib_Ofs5O8_lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop(columns=['Label','bangla_speech','region_name'])\n",
        "y = df['Label']\n",
        "\n",
        "df_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "df_test, df_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the sizes of the resulting datasets\n",
        "print(\"Training set size:\", len(df_train))\n",
        "print(\"Testing set size:\", len(df_test))\n",
        "print(\"Validation set size:\", len(df_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-4Rd5Ep9DZI",
        "outputId": "d25f33c0-4c14-4346-d279-f0b4c0ec8b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 9375\n",
            "Testing set size: 2500\n",
            "Validation set size: 625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train, y_train], axis=1)\n",
        "df_test = pd.concat([df_test, y_test], axis=1)\n",
        "df_val = pd.concat([df_val, y_val], axis=1)"
      ],
      "metadata": {
        "id": "TqemmHFABrBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer bert"
      ],
      "metadata": {
        "id": "3APxXYrDS85N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"csebuetnlp/banglishbert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "jZfdHo735Awg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "17360b7ef07640dca2931ebb7a891841",
            "8e2310e5f5ff4105a48b76ab784d068c",
            "19886869b4b94802a612f44ebb299849",
            "1681e6159a694e90bcc26e94afa5a9a9",
            "1eabe4aa8d5d436cba147f02475cc0bc",
            "8464ab553314462fbdaf5672138ca7c3",
            "583401a6954c412db6d2155a14626aed",
            "b1e74196bab54bfcaaa147a1895d9aca",
            "c6694c874a964a2ba45061a0789b5bb2",
            "592692554e7848109596aae2fe6fc09c",
            "f48deab31563474f842c720a4b577fd5",
            "c9d93e9754e443b4b5cba30b8d80cea0",
            "ef6cab0ad32e46129cd74d4f594c70ba",
            "e30a8dd8b13a4d7c8ff71ba152292905",
            "b3a29671a0a8473eae45cdb35540b7eb",
            "b7ef822eeff349cf88197bd881fa2228",
            "1f6230a4e4d6434bba7981376b95bf78",
            "d722a9d579d448d591b9d348a697c63f",
            "b43de5aa767d41c991c61caf7816f9f9",
            "be998074d37448789b0640c73dc27e41",
            "c3c72beccc574030921ed2f1b91bac4d",
            "7c8949c867044ea9b6e2cff115cbb679",
            "0cfed3bc646a4bb482d257f42e4b5577",
            "73ef010a36474f4f8928b2433417ca36",
            "c6a6fa6937fb4707be1257f522fdd6c3",
            "73683e03d80742ca88d8e46fae1a8dc8",
            "4c5d170f58cb48f2b44a46892dbd26b4",
            "fe9609db4e4045c7a1175b88e2654b49",
            "2f594ed2cc7d49baa7208adb1f8325e2",
            "a78ecb11a0eb41e8b88ce2e1df52bf7e",
            "aebb5edd283844a0a1fe41b2b5948075",
            "2537105d5d4249f197b39f615e47d703",
            "1c54cf4d3ae44ee7a5c5c9c5837b7ccd",
            "6e036a9e54c34d5e962999939cba56ac",
            "d4ef2eca3e774932ab6ba814c2810944",
            "a502c20318004769a101a5048a01d8ce",
            "27448499e043416b87c9db04cd9dd64f",
            "c773441014a54719bd0800104d7021fe",
            "2ce58b5404294d6196bc49c4e8e05578",
            "405f27e33390440cab31be1007601639",
            "1100d1eaf190414a9fffbbdc3f23c798",
            "98d1c1c2639e4569ad63551b83ef17cd",
            "4f4c8e55315b46a0ba2bde28079f7c1d",
            "0fcdd1a0806b42b882288f8640754786"
          ]
        },
        "outputId": "082dbbe7-71f0-4c22-ce01-c91a7145cd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17360b7ef07640dca2931ebb7a891841"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/874 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9d93e9754e443b4b5cba30b8d80cea0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/366k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cfed3bc646a4bb482d257f42e4b5577"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e036a9e54c34d5e962999939cba56ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "Wcz1K8yP5HbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, comments, targets, tokenizer, max_len):\n",
        "    self.comments = comments\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comments)\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.comments[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'Data': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "u9wRy5pD8EdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmo-svdX8PlQ",
        "outputId": "01a69e7b-b087-4fd4-ec2c-86a1c495ce2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9375, 2), (625, 2), (2500, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    comments=df.Data.to_numpy(),\n",
        "    targets=df.Label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len,\n",
        "\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=True\n",
        "  )"
      ],
      "metadata": {
        "id": "UNl1EIoK8SSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNIS8cdn8UnG",
        "outputId": "d229ae2c-9781-4d31-ddcc-2a5781b3b208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_0HrOWu8XNi",
        "outputId": "36e8b103-c27a-4509-dd40-4493797d2ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Data', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX6ijgPU8ZXz",
        "outputId": "a9fe00b1-9e41-4e4b-804f-f0c3821c7dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = AutoModelForPreTraining.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "VoQnAw7K8bdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4de7414f452e4baabd302680cb562d62",
            "c16c2f800ad448ae92b16e768713fe3f",
            "48aa0d3d97b54f19ab41c3243947a385",
            "0c229ddd416d4fc9863454929c573a8a",
            "bf5ad777a7a940baa79d06931c98e101",
            "9bd28990aedd4dfd9d1c3976c1523ff4",
            "6ff67cbee5324308bc4e2da4bae018f5",
            "0552b01741474455acf4ed834a887a04",
            "bb4c3d211c8d4c7c825bc3c0b4f9614b",
            "4fa095e8b731425fa629879e29dfc55a",
            "0b66705ec7d74c648b619e49fa3db9a5"
          ]
        },
        "outputId": "d2aa4b70-4d8d-4404-9bc0-2e776af69e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4de7414f452e4baabd302680cb562d62"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class sentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(sentimentClassifier, self).__init__()\n",
        "        self.electra = AutoModelForPreTraining.from_pretrained(model_name)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(128, n_classes)  # Adjust the input size\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        pooled_output = outputs.logits  # Access logits for pooled output\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n"
      ],
      "metadata": {
        "id": "LD1DPU6b8jyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "wAVVIZ_M8jwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5M8EGn8jtf",
        "outputId": "15c81c62-3db4-48ab-fd9e-5a8b55469752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=True)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=4,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsiwzaFx8jrL",
        "outputId": "468ee2c1-1a52-4f05-cfa4-d33b733e42d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  #tqdm for progress monitoring\n",
        "  data_loader = tqdm(data_loader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    data_loader.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "7R2IPh5J83R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "\n",
        "    data_loader = tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Update tqdm description with the current loss\n",
        "            data_loader.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "WvbOHR-z83PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from collections import defaultdict\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'\\nTrain loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'\\nVal   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkjxIfbZ83MI",
        "outputId": "62541c78-eb52-49e3-c6c0-28b961ee105a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:13<00:00,  3.03batch/s, loss=1.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 1.1956365305815948 accuracy 0.4944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.10batch/s, loss=0.641]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.6407181642949581 accuracy 0.7344\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:21<00:00,  2.90batch/s, loss=0.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.5896261773444077 accuracy 0.7773866666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.25batch/s, loss=0.429]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.4289192530006403 accuracy 0.8384\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:21<00:00,  2.90batch/s, loss=0.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.38024092143013716 accuracy 0.8623999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.29batch/s, loss=0.446]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.44620263106189667 accuracy 0.872\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:21<00:00,  2.90batch/s, loss=0.276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.2764106050754322 accuracy 0.9024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.26batch/s, loss=0.502]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.501831952820794 accuracy 0.8576\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:21<00:00,  2.90batch/s, loss=0.217]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.2167553363999955 accuracy 0.9265066666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.30batch/s, loss=0.545]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.545143972901856 accuracy 0.8768\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:20<00:00,  2.93batch/s, loss=0.155]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.15518988066327774 accuracy 0.9496533333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.29batch/s, loss=0.723]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.7234292186780976 accuracy 0.8768\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:19<00:00,  2.94batch/s, loss=0.122]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.12150528620811159 accuracy 0.9642666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.17batch/s, loss=1.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.024265601675824 accuracy 0.872\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:19<00:00,  2.94batch/s, loss=0.0999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.09986001394685315 accuracy 0.97408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.29batch/s, loss=1.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.2927536600439737 accuracy 0.8672000000000001\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:19<00:00,  2.94batch/s, loss=0.0793]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.0793122525046541 accuracy 0.9800533333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.25batch/s, loss=1.37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.3663458278868348 accuracy 0.8768\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:19<00:00,  2.94batch/s, loss=0.056]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.056014045695786295 accuracy 0.9847466666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:04<00:00,  8.05batch/s, loss=1.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.3877383087296038 accuracy 0.8736\n",
            "\n",
            "CPU times: user 22min 51s, sys: 10min 20s, total: 33min 11s\n",
            "Wall time: 34min 17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQmpaKiCg6K",
        "outputId": "bb6c16df-3e1e-4c42-d0bc-0674b73be693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/157 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 157/157 [00:18<00:00,  8.55batch/s, loss=1.3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.882"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  toxic_comments = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"Data\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      toxic_comments.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return toxic_comments, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "Nmyx3bkDRYuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "id": "xIcGzGVFRgNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6719f7-5b72-4cfe-9ed4-2bb78dfdf015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names,digits=4))\n"
      ],
      "metadata": {
        "id": "LtVHMfSpRiIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1239c2ad-6b1a-4dd3-b567-56e00a9b4a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Barishal     0.8975    0.9080    0.9027       511\n",
            "  Chittagong     0.9528    0.9098    0.9308       488\n",
            "  Mymensingh     0.8430    0.8480    0.8455       513\n",
            "    Noakhali     0.8646    0.8543    0.8594       501\n",
            "      Sylhet     0.8577    0.8912    0.8741       487\n",
            "\n",
            "    accuracy                         0.8820      2500\n",
            "   macro avg     0.8831    0.8823    0.8825      2500\n",
            "weighted avg     0.8828    0.8820    0.8822      2500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_percentage = accuracy * 100\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Define the custom palette\n",
        "custom_palette = sns.light_palette(\"DarkOliveGreen\", as_cmap=True)\n",
        "# Define custom font dictionary for title and labels\n",
        "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
        "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 10}\n",
        "\n",
        "# Create heatmap with annotations and colormap\n",
        "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,\n",
        "                      xticklabels=class_names, yticklabels=class_names,\n",
        "                      annot_kws={\"family\": \"Serif\", 'color':'black','weight': 'bold', 'size': 13})\n",
        "\n",
        "# Set x and y labels with the custom font dictionary\n",
        "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
        "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
        "heatmap.set_title('Sentiment classification \\nAccuracy: {:.2f}%'.format(accuracy_percentage),\n",
        "                  fontdict=font, pad=12)\n",
        "\n",
        "# Set font properties for tick labels on both axes\n",
        "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
        "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
        "\n",
        "# Create a color bar to indicate the scale\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=10)\n",
        "# Adjust padding between x-axis label and x-axis ticks\n",
        "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "akmWxmGmRlkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "76302b83-58f3-4ec1-b7e3-c6d49279b926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aBb4PviNUxRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}