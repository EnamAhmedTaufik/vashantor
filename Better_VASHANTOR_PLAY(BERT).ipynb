{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "nn8k6qv5P1hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install dataprep"
      ],
      "metadata": {
        "id": "O6ZzcomJP0wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer"
      ],
      "metadata": {
        "id": "fpdKhC18Q5Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==2.1.4\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "tWBNEroP-xJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3htvK8w9jCZ",
        "outputId": "bde5eee1-3b09-48fb-edfe-b481f661f193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        output = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], encoding='utf-8')\n",
        "        gpu_name = output.strip()\n",
        "        return gpu_name\n",
        "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "        return None\n",
        "print(get_gpu_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5TIYMSa9jAA",
        "outputId": "1b01374d-b6fa-49a8-ac18-527fd4207ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1D1StYK9i9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Mount"
      ],
      "metadata": {
        "id": "LW7oiuVLPyTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUlIqmd_StaD",
        "outputId": "19391368-b375-45f8-ecd7-49da4c15862e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "m_hZ7kfPawO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0pnPOcIA_Re"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoModelForPreTraining, AutoTokenizer\n",
        "from normalizer import normalize\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "#from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n"
      ],
      "metadata": {
        "id": "WVIjBhUp-sg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "GwNwsh2bRvWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ru3sH9BqLG",
        "outputId": "614bd680-7a9b-4a8a-fb35-110772a8808b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "BZtU1z5FH5VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Barishal Train Translation.csv\")\n",
        "ctg_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Chittagong Train Translation.csv\")\n",
        "mymensingh_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Mymensingh Train Translation.csv\")\n",
        "nohakhali_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Noakhali Train Translation.csv\")\n",
        "sylhet_train_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Train/Sylhet Train Translation.csv\")"
      ],
      "metadata": {
        "id": "JjyEqfqrBqIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Barishal  Validation Translation.csv\")\n",
        "ctg_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Chittagong Validation Translation.csv\")\n",
        "mymensingh_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Mymensingh Validation Translation.csv\")\n",
        "nohakhali_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Noakhali Validation Translation.csv\")\n",
        "sylhet_valid_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Validation/Sylhet Validation Translation.csv\")"
      ],
      "metadata": {
        "id": "1W5dEm5IMk48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Barishal Test Translation.csv\")\n",
        "ctg_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Chittagong Test Translation.csv\")\n",
        "mymensingh_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Mymensingh Test Translation.csv\")\n",
        "nohakhali_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Noakhali Test Translation.csv\")\n",
        "sylhet_test_df = pd.read_csv(\"/content/drive/MyDrive/On going Research/VASHANTOR/Test/Sylhet Test Translation.csv\")"
      ],
      "metadata": {
        "id": "hr-qXJb6Ml8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concate VASHANTOR DATASET (Train, valid, test)"
      ],
      "metadata": {
        "id": "Bimyvu64NoE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df = pd.concat([barishal_train_df, barishal_valid_df, barishal_test_df])\n",
        "ctg_train_df = pd.concat([ctg_train_df, ctg_valid_df, ctg_test_df])\n",
        "mymensingh_train_df = pd.concat([mymensingh_train_df, mymensingh_valid_df, mymensingh_test_df])\n",
        "nohakhali_train_df = pd.concat([nohakhali_train_df, nohakhali_valid_df, nohakhali_test_df])\n",
        "sylhet_train_df = pd.concat([sylhet_train_df, sylhet_valid_df, sylhet_test_df])"
      ],
      "metadata": {
        "id": "ID1aOzyFM_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "U4ow9qxVBqGK",
        "outputId": "420bb3c8-b46d-4180-9bf7-3859c3149959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            bangla_speech   \\\n",
              "0                               কেমন আছো ?   \n",
              "1                    আজকে আমার মন ভালো নেই   \n",
              "2                            তুমি কি করো ?   \n",
              "3           এই গরমে আমার কিছু ভালো লাগে না   \n",
              "4  ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল   \n",
              "\n",
              "                                banglish_speech   \\\n",
              "0                                    kemon acho?   \n",
              "1                          ajke amr mon valo nei   \n",
              "2                                 tumi ki koro?    \n",
              "3              ei gorome amar kichu valo lage na   \n",
              "4  cheleti sada ronger ekti shirt pore eshechilo   \n",
              "\n",
              "                             barishal_bangla_speech   \\\n",
              "0                                        আসো কোরোহম?   \n",
              "1                               আইজ মোর মনডা ভালোনা    \n",
              "2                                      ও মোনু হর কি?   \n",
              "3             এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...   \n",
              "\n",
              "                           barishal_banglish_speech  region_name   \\\n",
              "0                                       Aso korohom?    Barishal    \n",
              "1                               aij mor monda valona    Barishal    \n",
              "2                                    o monu horo ki?    Barishal    \n",
              "3           ei thada pora gorome mor kissu vallagena    Barishal    \n",
              "4  polaugga eukka dhola rong er eukka gunji poirr...    Barishal    \n",
              "\n",
              "                       english_speech  \n",
              "0                        How are you?  \n",
              "1          I'm not feeling well today  \n",
              "2                  what are you doing  \n",
              "3   I don't like anything this summer  \n",
              "4  The boy came wearing a white shirt  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48375e46-44a7-46b9-9650-b2333ac98797\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>banglish_speech</th>\n",
              "      <th>barishal_bangla_speech</th>\n",
              "      <th>barishal_banglish_speech</th>\n",
              "      <th>region_name</th>\n",
              "      <th>english_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো ?</td>\n",
              "      <td>kemon acho?</td>\n",
              "      <td>আসো কোরোহম?</td>\n",
              "      <td>Aso korohom?</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>How are you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে আমার মন ভালো নেই</td>\n",
              "      <td>ajke amr mon valo nei</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>aij mor monda valona</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>I'm not feeling well today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তুমি কি করো ?</td>\n",
              "      <td>tumi ki koro?</td>\n",
              "      <td>ও মোনু হর কি?</td>\n",
              "      <td>o monu horo ki?</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>what are you doing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>এই গরমে আমার কিছু ভালো লাগে না</td>\n",
              "      <td>ei gorome amar kichu valo lage na</td>\n",
              "      <td>এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>ei thada pora gorome mor kissu vallagena</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>I don't like anything this summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল</td>\n",
              "      <td>cheleti sada ronger ekti shirt pore eshechilo</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...</td>\n",
              "      <td>polaugga eukka dhola rong er eukka gunji poirr...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>The boy came wearing a white shirt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48375e46-44a7-46b9-9650-b2333ac98797')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48375e46-44a7-46b9-9650-b2333ac98797 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48375e46-44a7-46b9-9650-b2333ac98797');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4ab4bc0d-f0f9-463f-b676-08b5b88c93a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ab4bc0d-f0f9-463f-b676-08b5b88c93a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4ab4bc0d-f0f9-463f-b676-08b5b88c93a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgix2qADvCY",
        "outputId": "5c908942-889d-43df-b63a-1531bbb5c2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'barishal_bangla_speech ',\n",
              "       'barishal_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctg_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqtYoUU1D5Iu",
        "outputId": "0e1a0ea8-e6af-48ad-ed8b-92de05652018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'chittagong_bangla_speech ',\n",
              "       'chittagong_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mymensingh_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU74zvbPD5F2",
        "outputId": "4b3782cf-05a1-4963-fe34-acd8e7368fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'mymensingh_bangla_speech ',\n",
              "       'mymensingh_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nohakhali_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDq4VG8hD5Cu",
        "outputId": "a25b5b19-50af-41f7-f711-ea43806ba2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'noakhali_bangla_speech ',\n",
              "       'noakhali_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8ALmdhlD_qb",
        "outputId": "b38de638-63b9-42be-fd2b-69f8cdb3ed24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'banglish_speech ', 'sylhet_bangla_speech ',\n",
              "       'sylhet_banglish_speech ', 'region_name ', 'english_speech'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Columns"
      ],
      "metadata": {
        "id": "9rAw9DZVIBK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.drop(columns=['banglish_speech ', 'barishal_banglish_speech ', 'english_speech'], inplace=True)\n",
        "ctg_train_df.drop(columns=['banglish_speech ', 'chittagong_banglish_speech ', 'english_speech'], inplace=True)\n",
        "mymensingh_train_df.drop(columns=['banglish_speech ', 'mymensingh_banglish_speech ', 'english_speech'], inplace=True)\n",
        "nohakhali_train_df.drop(columns=['banglish_speech ', 'noakhali_banglish_speech ', 'english_speech'], inplace=True)\n",
        "sylhet_train_df.drop(columns=['banglish_speech ', 'sylhet_banglish_speech ', 'english_speech'], inplace=True)\n"
      ],
      "metadata": {
        "id": "YtQLkxAVBp-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rename Columns from xyz_bangla_speech to regional_text"
      ],
      "metadata": {
        "id": "7_A0MzI6IFHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barishal_train_df.rename(columns={'barishal_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "ctg_train_df.rename(columns={'chittagong_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "mymensingh_train_df.rename(columns={'mymensingh_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "nohakhali_train_df.rename(columns={'noakhali_bangla_speech ': 'regional_text'}, inplace=True)\n",
        "sylhet_train_df.rename(columns={'sylhet_bangla_speech ': 'regional_text'}, inplace=True)"
      ],
      "metadata": {
        "id": "-ZqZXAPdGexC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Topj0NUC23p8",
        "outputId": "ce3f5f4d-6a3e-4f1d-81a5-b370e5da741b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'regional_text', 'region_name '], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSu3xJ7Y29a9",
        "outputId": "5e6609af-82e6-49c4-ea09-4ca378496658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sylhet', 'Sylhet '], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '] = sylhet_train_df['region_name '].replace('Sylhet ', 'Sylhet')\n"
      ],
      "metadata": {
        "id": "Fjr5ZRtM3Lm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sylhet_train_df['region_name '].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmBt8n_y3iZ4",
        "outputId": "5a5d13e5-619e-4e86-d332-85f2ea2b59e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sylhet'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concate all regional text"
      ],
      "metadata": {
        "id": "YyovFntJINYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([barishal_train_df, ctg_train_df, mymensingh_train_df, nohakhali_train_df, sylhet_train_df])"
      ],
      "metadata": {
        "id": "F34wOGtOBp7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.head(7000)"
      ],
      "metadata": {
        "id": "ga8EJ0e-Bp5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "_Gp1klrjJAwj",
        "outputId": "080c25b3-6fd7-4edf-ccbb-616692b8015f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        bangla_speech   \\\n",
              "125                           সে সবসময় মিথ্যা কথা বলতো   \n",
              "126                             সবাই তাকে অনেক ভয় পেতো   \n",
              "127                             কেউ তাকে ভালোবাসতো নাহ   \n",
              "128                                  সে খুবই খারাপ ছিল   \n",
              "129  গ্রামের মানুষরা ছেলেটির থেকে দূরে থাকতে চেষ্টা...   \n",
              "..                                                 ...   \n",
              "370       তুমি কি আমাকে এক গ্লাস পানি এনে দিতে পারবে ?   \n",
              "371                            আমি পারবো না পানি দিতে    \n",
              "372                   তোমার ভাই পড়ালেখাতে অনেক মেধাবি    \n",
              "373               আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা?    \n",
              "374                 সামনের দিকে যেয়ে মেয়েটি অনেক হাসবে   \n",
              "\n",
              "                                         regional_text region_name   \n",
              "125                          হে হখল সময় মিছা মাত মাততো       Sylhet  \n",
              "126                              হখলে তারে খুব ডরাইতো        Sylhet  \n",
              "127                             কেউ তারে বালা পাইতো না       Sylhet  \n",
              "128                                    হে বউত বাদ আছিল       Sylhet  \n",
              "129  গ্রাম ওর মাইনষে ফুয়া ওগুর তনে দূরে থাকার চেষ্ট...       Sylhet  \n",
              "..                                                 ...          ...  \n",
              "370      তুমি কি আমারে এক গ্লাস ফানি এনে দিতায় ফারবা?        Sylhet  \n",
              "371                             আমি পারবো না ফানি দিতে       Sylhet  \n",
              "372                    তোমার ভাই ফড়ালেখাতে বহুত মেধাবি       Sylhet  \n",
              "373                আইচ্চা কও দেখি বাঙলাদেশো কয়টা জেলা?       Sylhet  \n",
              "374                 সামনর দিকে যাইয়া ফুড়িটা বহুত হাসবো       Sylhet  \n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79f214d5-c0cc-455e-aca0-9c3a682bf43d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>সে সবসময় মিথ্যা কথা বলতো</td>\n",
              "      <td>হে হখল সময় মিছা মাত মাততো</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>সবাই তাকে অনেক ভয় পেতো</td>\n",
              "      <td>হখলে তারে খুব ডরাইতো</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>কেউ তাকে ভালোবাসতো নাহ</td>\n",
              "      <td>কেউ তারে বালা পাইতো না</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>সে খুবই খারাপ ছিল</td>\n",
              "      <td>হে বউত বাদ আছিল</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>গ্রামের মানুষরা ছেলেটির থেকে দূরে থাকতে চেষ্টা...</td>\n",
              "      <td>গ্রাম ওর মাইনষে ফুয়া ওগুর তনে দূরে থাকার চেষ্ট...</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>তুমি কি আমাকে এক গ্লাস পানি এনে দিতে পারবে ?</td>\n",
              "      <td>তুমি কি আমারে এক গ্লাস ফানি এনে দিতায় ফারবা?</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>আমি পারবো না পানি দিতে</td>\n",
              "      <td>আমি পারবো না ফানি দিতে</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>তোমার ভাই পড়ালেখাতে অনেক মেধাবি</td>\n",
              "      <td>তোমার ভাই ফড়ালেখাতে বহুত মেধাবি</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>আচ্ছা বলো দেখি বাংলাদেশে কয়টি জেলা?</td>\n",
              "      <td>আইচ্চা কও দেখি বাঙলাদেশো কয়টা জেলা?</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>সামনের দিকে যেয়ে মেয়েটি অনেক হাসবে</td>\n",
              "      <td>সামনর দিকে যাইয়া ফুড়িটা বহুত হাসবো</td>\n",
              "      <td>Sylhet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79f214d5-c0cc-455e-aca0-9c3a682bf43d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79f214d5-c0cc-455e-aca0-9c3a682bf43d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79f214d5-c0cc-455e-aca0-9c3a682bf43d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-05e9e470-fa4a-4797-ac3d-00e2e263a562\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05e9e470-fa4a-4797-ac3d-00e2e263a562')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-05e9e470-fa4a-4797-ac3d-00e2e263a562 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode region_name column"
      ],
      "metadata": {
        "id": "FF0c56bDIgPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HHgsANNJNYa",
        "outputId": "76dc883f-0b94-45ef-cec5-00394e23299c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bangla_speech ', 'regional_text', 'region_name '], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'bangla_speech ': 'bangla_speech'}, inplace=True)\n",
        "df.rename(columns={'region_name ': 'region_name'}, inplace=True)"
      ],
      "metadata": {
        "id": "LoeSXWm5RvkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['region_encoded'] = label_encoder.fit_transform(df['region_name'])"
      ],
      "metadata": {
        "id": "fbZs91_7Bp3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_name'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ6_TArJIy6Q",
        "outputId": "80bb4425-ebe4-4f2e-fcc8-19fd4ff1f327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Barishal ', 'Chittagong', 'Mymensingh', 'Noakhali', 'Sylhet'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_encoded'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFhhenUbJVoB",
        "outputId": "3bc62d56-a21b-49e8-ff0a-4c548dcadf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.drop(columns=['region_name '], inplace=True)"
      ],
      "metadata": {
        "id": "nAWyh49dJieR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "jmYcIrA-KRxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('/content/drive/MyDrive/On going Research/VASHANTOR/combined_regional_text.csv', index=False)"
      ],
      "metadata": {
        "id": "69mMI0isi9hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Normalize"
      ],
      "metadata": {
        "id": "2af10LpEQeYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Puntuation**"
      ],
      "metadata": {
        "id": "F3iovqA0Ub-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations(text):\n",
        "  whitespace = re.compile(u\"[\\s\\u0020\\u00a0\\u1680\\u180e\\u202f\\u205f\\u3000\\u2000-\\u200d]+\", re.UNICODE)\n",
        "  bangla_fullstop = u\"\\u0964\"\n",
        "  text = re.sub(r'(^|\\s)@(\\w+)', r'\\1@user', text)\n",
        "  text = re.sub(r'\\bhttp?s://\\S+\\b', '', text)\n",
        "  punctSeq = u\"['\\\"“”‘’]+|[.?!,…]+|[:;]+\"\n",
        "  punc = u\"[(),$%^&*+={}\\[\\]:\\\"\\৷|\\'\\~`<>/,¦!?½£¶¼©⅐⅑⅒⅓⅔⅕⅖⅗⅘⅙⅚⅛⅜⅝⅞⅟↉¤¿º;-]+\"\n",
        "  text = whitespace.sub(\" \", text).strip()\n",
        "  text = re.sub(punctSeq, \" \", text)\n",
        "  text = re.sub(bangla_fullstop, \" \", text)\n",
        "  text = re.sub(punc, \" \", text)\n",
        "  text = re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]', ' ', text)\n",
        "  result = re.sub(r'\\b[a-zA-Z]+\\b', '', text)\n",
        "  text=text.replace(\"\\\\\", \" \")\n",
        "  normalized = normalize(text)\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "v3cVC2_zQhtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bangla_speech'] = df['bangla_speech'].apply(remove_punctuations)\n",
        "df['regional_text'] = df['regional_text'].apply(remove_punctuations)"
      ],
      "metadata": {
        "id": "Kng1G4QgT0Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis Data"
      ],
      "metadata": {
        "id": "MOD2qhPBKWyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "teitE7ePQhyG",
        "outputId": "34678ba9-10a1-443c-c900-a5266116770d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       bangla_speech  \\\n",
              "0                                         কেমন আছো     \n",
              "1                              আজকে আমার মন ভালো নেই   \n",
              "2                                      তুমি কি করো     \n",
              "3                     এই গরমে আমার কিছু ভালো লাগে না   \n",
              "4            ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল   \n",
              "5  মেয়েটি লাল রঙয়ের শাড়ি পরে আমার সাথে দেখা করতে ...   \n",
              "6                      ছেলেটি সিলেট থেকে ঢাকায় এসেছে   \n",
              "7     মেয়েটি সিলেট থেকে আসা এই ছেলেটিকে অনেক ভালবাসে   \n",
              "8          ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি   \n",
              "9  মেয়েটি তাঁর সব স্বপ্নের মধ্যে ছেলেটাকে কল্পনা করে   \n",
              "\n",
              "                                       regional_text region_name  \\\n",
              "0                                        আসো কোরোহম    Barishal    \n",
              "1                                আইজ মোর মনডা ভালোনা   Barishal    \n",
              "2                                      ও মোনু হর কি    Barishal    \n",
              "3             এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   Barishal    \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...   Barishal    \n",
              "5  মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...   Barishal    \n",
              "6                   পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে   Barishal    \n",
              "7  মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...   Barishal    \n",
              "8      পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই   Barishal    \n",
              "9  মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...   Barishal    \n",
              "\n",
              "   region_encoded  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  \n",
              "5               0  \n",
              "6               0  \n",
              "7               0  \n",
              "8               0  \n",
              "9               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff72b9a5-0ae7-4aa2-9aca-c3e24f7bb3f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "      <th>region_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>আসো কোরোহম</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে আমার মন ভালো নেই</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>তুমি কি করো</td>\n",
              "      <td>ও মোনু হর কি</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>এই গরমে আমার কিছু ভালো লাগে না</td>\n",
              "      <td>এই থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের একটি শার্ট পরে এসেছিল</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এর এউক্কা গুন্জি পইর্রা...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>মেয়েটি লাল রঙয়ের শাড়ি পরে আমার সাথে দেখা করতে ...</td>\n",
              "      <td>মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ছেলেটি সিলেট থেকে ঢাকায় এসেছে</td>\n",
              "      <td>পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>মেয়েটি সিলেট থেকে আসা এই ছেলেটিকে অনেক ভালবাসে</td>\n",
              "      <td>মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি</td>\n",
              "      <td>পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>মেয়েটি তাঁর সব স্বপ্নের মধ্যে ছেলেটাকে কল্পনা করে</td>\n",
              "      <td>মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff72b9a5-0ae7-4aa2-9aca-c3e24f7bb3f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff72b9a5-0ae7-4aa2-9aca-c3e24f7bb3f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff72b9a5-0ae7-4aa2-9aca-c3e24f7bb3f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b48f257-90fc-4e45-99fa-9307507b4b07\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b48f257-90fc-4e45-99fa-9307507b4b07')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b48f257-90fc-4e45-99fa-9307507b4b07 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Stopwords**"
      ],
      "metadata": {
        "id": "lJmwHybEUhN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('bengali'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcgEU08a6oz",
        "outputId": "093d7fc7-610b-4dbf-da67-5befd544196e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stop_words_remover(text):\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    without_stop_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    without_stop_word_text = ' '.join(without_stop_words)\n",
        "\n",
        "    return without_stop_word_text\n"
      ],
      "metadata": {
        "id": "3M-MpbxPa5i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bangla_speech'] = df['bangla_speech'].apply(stop_words_remover)\n",
        "df['regional_text'] = df['regional_text'].apply(stop_words_remover)"
      ],
      "metadata": {
        "id": "rOiSw2GaaUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "gF9iPilzbgM-",
        "outputId": "735b71a8-a623-4ecc-c9ba-b02fc4d15a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               bangla_speech  \\\n",
              "0                                   কেমন আছো   \n",
              "1                               আজকে মন ভালো   \n",
              "2                                        করো   \n",
              "3                             গরমে ভালো লাগে   \n",
              "4             ছেলেটি সাদা রঙয়ের শার্ট এসেছিল   \n",
              "5          মেয়েটি লাল রঙয়ের শাড়ি সাথে এসেছিল   \n",
              "6                   ছেলেটি সিলেট ঢাকায় এসেছে   \n",
              "7          মেয়েটি সিলেট আসা ছেলেটিকে ভালবাসে   \n",
              "8  ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি   \n",
              "9            মেয়েটি স্বপ্নের ছেলেটাকে কল্পনা   \n",
              "\n",
              "                                       regional_text region_name  \\\n",
              "0                                         আসো কোরোহম   Barishal    \n",
              "1                                আইজ মোর মনডা ভালোনা   Barishal    \n",
              "2                                            মোনু হর   Barishal    \n",
              "3                থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা   Barishal    \n",
              "4  পলাউগ্গা এউক্কা ধলা রং এউক্কা গুন্জি পইর্রা আইসেল   Barishal    \n",
              "5  মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...   Barishal    \n",
              "6                   পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে   Barishal    \n",
              "7  মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...   Barishal    \n",
              "8      পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই   Barishal    \n",
              "9  মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...   Barishal    \n",
              "\n",
              "   region_encoded  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  \n",
              "5               0  \n",
              "6               0  \n",
              "7               0  \n",
              "8               0  \n",
              "9               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-309ac14f-7d64-4e4d-a613-cf70e0230d94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>regional_text</th>\n",
              "      <th>region_name</th>\n",
              "      <th>region_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>আসো কোরোহম</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আজকে মন ভালো</td>\n",
              "      <td>আইজ মোর মনডা ভালোনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>করো</td>\n",
              "      <td>মোনু হর</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>গরমে ভালো লাগে</td>\n",
              "      <td>থাডা পরা গরমে মোর কিস্সু ভাল্লাগেনা</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ছেলেটি সাদা রঙয়ের শার্ট এসেছিল</td>\n",
              "      <td>পলাউগ্গা এউক্কা ধলা রং এউক্কা গুন্জি পইর্রা আইসেল</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>মেয়েটি লাল রঙয়ের শাড়ি সাথে এসেছিল</td>\n",
              "      <td>মাইআউগ্গা লাল রুঙ্গা শাড়ি পইর্রা মর লগে দেহা হ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ছেলেটি সিলেট ঢাকায় এসেছে</td>\n",
              "      <td>পলাউগ্গা শ্যলেত দিয়া ধাহা আইসেলে</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>মেয়েটি সিলেট আসা ছেলেটিকে ভালবাসে</td>\n",
              "      <td>মাইআউগ্গা শ্যলেত দিআ আঔআ পলাউগ্গারে আক্সের ভাল...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ছেলেটি মেয়েটাকে এখনো ভালবাসার চোখে দেখেনি</td>\n",
              "      <td>পলাউগ্গা মাইআউগ্গারে আহন ভালপাঔআর ছহে দেহেনাই</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>মেয়েটি স্বপ্নের ছেলেটাকে কল্পনা</td>\n",
              "      <td>মাইআউগ্গা হেয়ার শব হপ্পনের মইদ্ধে পলাউগ্গারে ...</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-309ac14f-7d64-4e4d-a613-cf70e0230d94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-309ac14f-7d64-4e4d-a613-cf70e0230d94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-309ac14f-7d64-4e4d-a613-cf70e0230d94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aeb37c00-dae9-441f-b8dd-ceb16e42789f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aeb37c00-dae9-441f-b8dd-ceb16e42789f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aeb37c00-dae9-441f-b8dd-ceb16e42789f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kt427H5KThU",
        "outputId": "a426cee8-beef-468e-ebf3-d414c67d8874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBvkw17O4Y8",
        "outputId": "74ab7512-38cb-452c-8502-740addee885e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 12500 entries, 0 to 374\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   bangla_speech   12500 non-null  object\n",
            " 1   regional_text   12500 non-null  object\n",
            " 2   region_name     12500 non-null  object\n",
            " 3   region_encoded  12500 non-null  int64 \n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 488.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['region_name'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IogpvwGI11l7",
        "outputId": "ecd95032-f3d9-416e-848d-ae255bce7af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Barishal      2500\n",
              "Chittagong    2500\n",
              "Mymensingh    2500\n",
              "Noakhali      2500\n",
              "Sylhet        2500\n",
              "Name: region_name, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJfgIOCPNJC",
        "outputId": "cac2e4fc-e136-4052-cde0-1d5178d62170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bangla_speech     0\n",
              "regional_text     0\n",
              "region_name       0\n",
              "region_encoded    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_regions = df['region_name'].value_counts()\n",
        "plt.figure(figsize=(6, 6))\n",
        "unique_regions.plot(kind='bar', color='skyblue')\n",
        "plt.title('Count of Unique Region Names')\n",
        "plt.xlabel('Region Name')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "ws2hUFRTKefk",
        "outputId": "955de33c-5327-4e2e-dc72-ed9be06ce40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBpG47LX_wDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To implement model"
      ],
      "metadata": {
        "id": "Cgxrr7r4Ah9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'regional_text': 'Data'}, inplace=True)\n",
        "df.rename(columns={'region_encoded': 'Label'}, inplace=True)"
      ],
      "metadata": {
        "id": "rWpqu261AhoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "jMhYMjyQAvC8",
        "outputId": "d727076c-5ee2-4f2b-c314-56a2f085563f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  bangla_speech        Data region_name  Label\n",
              "0      কেমন আছো  আসো কোরোহম   Barishal       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0e50d5d-e0b0-4d30-a90b-68a4cfc05a33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bangla_speech</th>\n",
              "      <th>Data</th>\n",
              "      <th>region_name</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>কেমন আছো</td>\n",
              "      <td>আসো কোরোহম</td>\n",
              "      <td>Barishal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0e50d5d-e0b0-4d30-a90b-68a4cfc05a33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0e50d5d-e0b0-4d30-a90b-68a4cfc05a33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0e50d5d-e0b0-4d30-a90b-68a4cfc05a33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Barishal', 'Chittagong','Mymensingh','Noakhali','Sylhet']"
      ],
      "metadata": {
        "id": "hr-dOVft7mto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "0g8VNA7mcwvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Valid-Test"
      ],
      "metadata": {
        "id": "ib_Ofs5O8_lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop(columns=['Label','bangla_speech','region_name'])\n",
        "y = df['Label']\n",
        "\n",
        "df_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "df_test, df_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the sizes of the resulting datasets\n",
        "print(\"Training set size:\", len(df_train))\n",
        "print(\"Testing set size:\", len(df_test))\n",
        "print(\"Validation set size:\", len(df_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-4Rd5Ep9DZI",
        "outputId": "c4ef98be-8832-4fe8-9123-e44dc7fbf402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 9375\n",
            "Testing set size: 2500\n",
            "Validation set size: 625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train, y_train], axis=1)\n",
        "df_test = pd.concat([df_test, y_test], axis=1)\n",
        "df_val = pd.concat([df_val, y_val], axis=1)"
      ],
      "metadata": {
        "id": "TqemmHFABrBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer bert"
      ],
      "metadata": {
        "id": "3APxXYrDS85N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"csebuetnlp/banglabert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "jZfdHo735Awg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "Wcz1K8yP5HbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, comments, targets, tokenizer, max_len):\n",
        "    self.comments = comments\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comments)\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.comments[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'Data': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "u9wRy5pD8EdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmo-svdX8PlQ",
        "outputId": "d2d2d452-d53b-4df3-c970-7fb48956a735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9375, 2), (625, 2), (2500, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    comments=df.Data.to_numpy(),\n",
        "    targets=df.Label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len,\n",
        "\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=True\n",
        "  )"
      ],
      "metadata": {
        "id": "UNl1EIoK8SSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNIS8cdn8UnG",
        "outputId": "88776e81-1013-4b72-e9d2-67c10029d0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_0HrOWu8XNi",
        "outputId": "4d24d6bb-c0ea-416a-cd6f-17305de4e3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Data', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX6ijgPU8ZXz",
        "outputId": "824cc74e-6d84-403b-8758-7798a5fa1aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = AutoModelForPreTraining.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "VoQnAw7K8bdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(sentimentClassifier, self).__init__()\n",
        "        self.electra = AutoModelForPreTraining.from_pretrained(model_name)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(128, n_classes)  # Adjust the input size\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        pooled_output = outputs.logits  # Access logits for pooled output\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n"
      ],
      "metadata": {
        "id": "LD1DPU6b8jyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "wAVVIZ_M8jwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5M8EGn8jtf",
        "outputId": "90a27d2b-3904-4d91-b5a9-d5de9d097e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS =\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=True)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=4,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsiwzaFx8jrL",
        "outputId": "63d35cbc-1bdf-4471-e588-5e183663f25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  #tqdm for progress monitoring\n",
        "  data_loader = tqdm(data_loader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    data_loader.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "7R2IPh5J83R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "\n",
        "    data_loader = tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Update tqdm description with the current loss\n",
        "            data_loader.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "WvbOHR-z83PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from collections import defaultdict\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'\\nTrain loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'\\nVal   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkjxIfbZ83MI",
        "outputId": "4e9d1d4c-bd65-4469-8f6b-d83ba8112613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:38<00:00,  2.68batch/s, loss=1.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 1.38940450706783 accuracy 0.4053333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.34batch/s, loss=0.877]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.8773909568786621 accuracy 0.6816\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.70batch/s, loss=0.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.6496130707562479 accuracy 0.7575466666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.25batch/s, loss=0.531]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.5306974783539772 accuracy 0.8144\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.69batch/s, loss=0.404]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.40413144445158034 accuracy 0.8500266666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.37batch/s, loss=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.6250380091369152 accuracy 0.8288000000000001\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.69batch/s, loss=0.288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.2877918556374307 accuracy 0.8989866666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.23batch/s, loss=0.581]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.5814604931045324 accuracy 0.8560000000000001\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.69batch/s, loss=0.225]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.2253807361327897 accuracy 0.9246933333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.17batch/s, loss=0.727]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.7267701327800751 accuracy 0.8592000000000001\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.69batch/s, loss=0.162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.1624614282978537 accuracy 0.9486933333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.19batch/s, loss=0.963]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 0.9627857918558291 accuracy 0.8512000000000001\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.70batch/s, loss=0.139]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.13895298809178433 accuracy 0.9602133333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.30batch/s, loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.1077727522701024 accuracy 0.8512000000000001\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.70batch/s, loss=0.105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.10543012686124713 accuracy 0.96736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  6.98batch/s, loss=1.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.2778446628596611 accuracy 0.8560000000000001\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.69batch/s, loss=0.0857]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.08565780863886571 accuracy 0.9757866666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.35batch/s, loss=1.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.3031036303144972 accuracy 0.8608\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/586 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 586/586 [03:37<00:00,  2.69batch/s, loss=0.0694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss 0.06944224220657721 accuracy 0.9790933333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/40 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 40/40 [00:05<00:00,  7.18batch/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val   loss 1.3787395568765533 accuracy 0.8560000000000001\n",
            "\n",
            "CPU times: user 24min 56s, sys: 11min 22s, total: 36min 18s\n",
            "Wall time: 37min 40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQmpaKiCg6K",
        "outputId": "bff62ea5-9850-451b-c0d2-ecacc3fdf2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/157 [00:00<?, ?batch/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 157/157 [00:22<00:00,  7.00batch/s, loss=1.33]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8648"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  toxic_comments = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"Data\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      toxic_comments.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return toxic_comments, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "Nmyx3bkDRYuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIcGzGVFRgNr",
        "outputId": "c0ba814b-e9ef-443e-c643-17061e09a96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names,digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtVHMfSpRiIS",
        "outputId": "a6876620-f218-47e4-e7c9-bde29d65cbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Barishal     0.8986    0.8845    0.8915       511\n",
            "  Chittagong     0.9492    0.8811    0.9139       488\n",
            "  Mymensingh     0.8069    0.8713    0.8379       513\n",
            "    Noakhali     0.8449    0.8263    0.8355       501\n",
            "      Sylhet     0.8380    0.8604    0.8490       487\n",
            "\n",
            "    accuracy                         0.8648      2500\n",
            "   macro avg     0.8675    0.8647    0.8656      2500\n",
            "weighted avg     0.8671    0.8648    0.8654      2500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_percentage = accuracy * 100\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Define the custom palette\n",
        "custom_palette = sns.light_palette(\"DarkOliveGreen\", as_cmap=True)\n",
        "# Define custom font dictionary for title and labels\n",
        "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
        "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 10}\n",
        "\n",
        "# Create heatmap with annotations and colormap\n",
        "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,\n",
        "                      xticklabels=class_names, yticklabels=class_names,\n",
        "                      annot_kws={\"family\": \"Serif\", 'color':'black','weight': 'bold', 'size': 13})\n",
        "\n",
        "# Set x and y labels with the custom font dictionary\n",
        "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
        "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
        "heatmap.set_title('Sentiment classification \\nAccuracy: {:.2f}%'.format(accuracy_percentage),\n",
        "                  fontdict=font, pad=12)\n",
        "\n",
        "# Set font properties for tick labels on both axes\n",
        "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
        "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
        "\n",
        "# Create a color bar to indicate the scale\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=10)\n",
        "# Adjust padding between x-axis label and x-axis ticks\n",
        "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "akmWxmGmRlkb",
        "outputId": "5ebb07d2-783e-48a6-a3c5-5ab817e76268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aBb4PviNUxRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}